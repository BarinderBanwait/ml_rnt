{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: train a neural network model of good score to predict size of sha\n",
    "$$Recall = \\frac{True Positive(TP)}{Actually Positive(TP + FN)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import models\n",
    "import executor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import recall function from sklearn\n",
    "from sklearn.metrics import recall_score, matthews_corrcoef\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the big dataset with 60 a_p's and 52710 curves..\n"
     ]
    }
   ],
   "source": [
    "# load your data here. The following ensure this will work on Windows as well as Unix\n",
    "path = Path(\"..\") / \"data_files\" / \"ecq_sha_B_50_conds_1_8191.parquet\"\n",
    "df = utils.load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_kodaira_symbol(ks_list):\n",
    "    output = []\n",
    "    for ks in ks_list:\n",
    "        if ks >= 5:\n",
    "            output.append(5)\n",
    "        elif ks <= -5:\n",
    "            output.append(-5)\n",
    "        else:\n",
    "            output.append(ks)\n",
    "    return output\n",
    "\n",
    "df['kodaira_symbols'] = df['kodaira_symbols'].apply(normalise_kodaira_symbol).apply(set).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Use apply with a lambda function to check if 1 is in the list\n",
    "contains_1 = df['kodaira_symbols'].apply(lambda x: 1 in x)\n",
    "\n",
    "# Step 2: Use this boolean Series to index df\n",
    "df_1 = df[contains_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lmfdb_label</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>23</th>\n",
       "      <th>...</th>\n",
       "      <th>rank</th>\n",
       "      <th>torsion</th>\n",
       "      <th>adelic_level</th>\n",
       "      <th>adelic_index</th>\n",
       "      <th>adelic_genus</th>\n",
       "      <th>sha</th>\n",
       "      <th>kodaira_symbols</th>\n",
       "      <th>real_period</th>\n",
       "      <th>special_value</th>\n",
       "      <th>tamagawa_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lmfdb_label, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, conductor, rank, torsion, adelic_level, adelic_index, adelic_genus, sha, kodaira_symbols, real_period, special_value, tamagawa_product]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 62 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_608937/1151002872.py:11: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  df_dummies = df_dummies.sum(level=0)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the lists into separate rows\n",
    "df_split = df['kodaira_symbols'].apply(pd.Series)\n",
    "\n",
    "# Step 2: Stack the DataFrame to get a Series with a MultiIndex\n",
    "df_split = df_split.stack()\n",
    "\n",
    "# Step 3: Perform one-hot encoding\n",
    "df_dummies = pd.get_dummies(df_split, prefix='kodaira')\n",
    "\n",
    "# Step 4: Sum the DataFrame level-wise\n",
    "df_dummies = df_dummies.sum(level=0)\n",
    "\n",
    "# Step 5: Join the original DataFrame with the one-hot encoded DataFrame\n",
    "df = df.join(df_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('kodaira_symbols', axis=1, inplace=True)\n",
    "df.drop('lmfdb_label', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     50676\n",
       "4      1407\n",
       "9       409\n",
       "16      133\n",
       "25       56\n",
       "49       15\n",
       "64        6\n",
       "36        5\n",
       "81        3\n",
       "Name: sha, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sha'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input dimension is 68 and the output dimension is 9.\n",
      "Device: cpu.\n",
      "The model has 1,569 trainable parameters..\n",
      "VanillaNN(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=68, out_features=20, bias=True)\n",
      "    (1): Linear(in_features=20, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# choose model parameters\n",
    "hidden_units = [20]\n",
    "\n",
    "# default model parameters\n",
    "input_dim, output_dim = utils.get_input_output_dim(df, 'sha')\n",
    "\n",
    "# check if we have cuda available\n",
    "device = utils.get_device()\n",
    "\n",
    "# create model\n",
    "model = models.VanillaNN(input_dim, hidden_units, output_dim).to(device)\n",
    "\n",
    "# print model summary\n",
    "utils.model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose training parameters\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "import sklearn\n",
    "evaluator = sklearn.metrics.matthews_corrcoef\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_dataloader, val_dataset, test_dataset = utils.prepare_data(df,device)\n",
    "# train the model\n",
    "model, train_eval_hist, val_eval_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs,verbose=False)\n",
    "# plot train_eval_hist, val_eval_hist\n",
    "utils.plot_train_eval_hist(train_eval_hist, val_eval_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test recall_score: 0.7733068641673666\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "test_res = executor.test(model, test_dataset, evaluator, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the big dataset with 1000 a_p's and 2076146 curves..\n",
      "Converted the rank column to binary. The value of 1 means the rank is greater than 4, otherwise 0. Rank counts:\n",
      "     count\n",
      "0  1360505\n",
      "1   715641\n"
     ]
    }
   ],
   "source": [
    "# load your data here. The following ensure this will work on Windows as well as Unix\n",
    "path = Path(\"..\") / \"data_files\" / \"CustomDataset\" / \"custom_dataset.parquet\"\n",
    "df_custom_full = utils.load_data(path)\n",
    "df_custom_full.drop(columns=['conductor'],inplace=True)\n",
    "\n",
    "# convert the rank to binary classification\n",
    "df_custom_full = utils.convert_rank_to_binary(df_custom_full, threshold)\n",
    "\n",
    "X = df_custom_full.drop(columns=['rank']).values\n",
    "y = df_custom_full['rank'].values\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long).to(device)\n",
    "\n",
    "custom_full = TensorDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test recall_score: 0.7813466644918304\n"
     ]
    }
   ],
   "source": [
    "test_res = executor.test(model, custom_full, evaluator, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
