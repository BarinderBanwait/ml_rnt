{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import models\n",
    "import executor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from utils import perfect_square_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the dataset with 118 features and 3064705 curves..\n"
     ]
    }
   ],
   "source": [
    "# load your data here. The following ensure this will work on Windows as well as Unix\n",
    "# the data file has its Kodaira symbols already preprocessed \n",
    "path = Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000_kodaira_processed.parquet\"\n",
    "df = utils.load_data(path)\n",
    "\n",
    "# process kodaira symbol if it is not already done\n",
    "# path = Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000.parquet\"\n",
    "# df = utils.load_data(path)\n",
    "# df = utils.process_kodaira_symbol(df)\n",
    "# df.drop('lmfdb_label', axis=1, inplace=True)\n",
    "# df.to_parquet(Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000_kodaira_processed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    158758\n",
       "4    158758\n",
       "Name: sha, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get a balanced dataset with equal amount of 1 and 4 labels\n",
    "len_4 = df[df['sha'] == 4].shape[0]\n",
    "# df_balanced = df[df['sha'] == 1].sample(len_4) \n",
    "df_balanced = df[df['sha'] == 1].iloc[:len_4]\n",
    "df_balanced = pd.concat([df_balanced, df[df['sha'] == 4]])\n",
    "df_balanced.sha.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input dimension is 118 and the output dimension is 1.\n",
      "Device: cpu.\n",
      "The model has 26,049 trainable parameters..\n",
      "VanillaNN(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=118, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# choose model parameters\n",
    "hidden_units = [128,64,32]\n",
    "\n",
    "# default model parameters\n",
    "input_dim, output_dim = utils.get_input_output_dim(df_balanced, 'sha', if_regression=True)\n",
    "\n",
    "# check if we have cuda available\n",
    "device = utils.get_device()\n",
    "\n",
    "# create model\n",
    "model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.5, if_batchnorm=True).to(device)\n",
    "# model = models.VanillaNN(input_dim, hidden_units, output_dim).to(device)\n",
    "\n",
    "# print model summary\n",
    "utils.model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose training parameters\n",
    "loss_func = nn.MSELoss()\n",
    "num_epochs = 3\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "evaluator = perfect_square_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_balanced, 'sha', device, if_regression=True)\n",
    "# train the model\n",
    "model, train_eval_hist, val_eval_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=True, verbose=True)\n",
    "# plot train_eval_hist, val_eval_hist\n",
    "utils.plot_train_eval_hist(train_eval_hist, val_eval_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.test(model, test_dataset, evaluator, if_regression = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just load a trained model and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the dataset with 118 features and 3064705 curves..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.1147, grad_fn=<L1LossBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "path = Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000_kodaira_processed.parquet\"\n",
    "df = utils.load_data(path)\n",
    "\n",
    "# load torch model\n",
    "import torch\n",
    "model = torch.load(Path(\"..\") / \"trained_models\" / \"model.pth\")\n",
    "\n",
    "# split data\n",
    "train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_balanced, 'sha', device, if_regression=True)\n",
    "X_test, y_test = test_dataset.tensors\n",
    "\n",
    "# test the model\n",
    "model.eval()\n",
    "outputs = model(X_test)\n",
    "y_pred = outputs.squeeze()\n",
    "\n",
    "# get the l1 distance between the predicted and actual values\n",
    "loss = torch.nn.L1Loss()\n",
    "loss(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
