{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "307774",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This notebook is for a neural network (NN) on curves with size of Sha equal to 4 and 9 and removing one BSD feature at a time. This includes both the original and log-transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8479",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from lib import utils, models, executor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# fix the seed for reproducibility\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f32",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Create balanced dataset of elliptic curves with size of the Tate-Shafarevich group equal to 4 and 9 containing all BSD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50274b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the dataset with 120 features and 3064705 curves..\n"
     ]
    }
   ],
   "source": [
    "# load your data here. The following ensure this will work on Windows as well as Unix\n",
    "path = Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000_reg.parquet\"\n",
    "df = utils.load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57fb4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sha\n",
       "4    50428\n",
       "9    50428\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_9 = df[df['sha'] == 9].shape[0]\n",
    "df_balanced = df[df['sha'] == 4].sample(len_9, random_state=seed) \n",
    "df_balanced = pd.concat([df_balanced, df[df['sha'] == 9]])\n",
    "df_balanced.sha.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a706",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Get columns with all the BSD features, from which we will eventually remove one at a time\n",
    "bsd_features = ['special_value', 'torsion', 'real_period', 'regulator', 'tamagawa_product', 'sha']\n",
    "\n",
    "df_balanced_bsd = df_balanced[bsd_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e4fc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>special_value</th>\n",
       "      <th>torsion</th>\n",
       "      <th>real_period</th>\n",
       "      <th>regulator</th>\n",
       "      <th>tamagawa_product</th>\n",
       "      <th>sha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334625</th>\n",
       "      <td>2.19751</td>\n",
       "      <td>2</td>\n",
       "      <td>0.54938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086182</th>\n",
       "      <td>3.22805</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782926</th>\n",
       "      <td>3.98612</td>\n",
       "      <td>2</td>\n",
       "      <td>0.49826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484030</th>\n",
       "      <td>2.99537</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053287</th>\n",
       "      <td>2.23394</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         special_value  torsion  real_period  regulator  tamagawa_product  sha\n",
       "334625         2.19751        2      0.54938        1.0                 4    4\n",
       "1086182        3.22805        1      0.80701        1.0                 1    4\n",
       "1782926        3.98612        2      0.49826        1.0                 8    4\n",
       "2484030        2.99537        1      0.09361        1.0                 8    4\n",
       "3053287        2.23394        1      0.09308        1.0                 6    4"
      ]
     },
     "execution_count": 5,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_bsd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b68",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Delete one feature at a time on original data\n",
    "\n",
    "The best accuracy is about 97% when removing either the size of torsion or the regulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394d4a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07264c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model without special_value..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 89 with Training CrossEntropyLoss : 0.5473, Validation CrossEntropyLoss : 0.5517. Training accuracy_score : 0.7100, Validation accuracy_score : 0.7076, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.705\n",
      "----------------------------------\n",
      "Running model without torsion..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1103/125803182.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 80 with Training CrossEntropyLoss : 0.0953, Validation CrossEntropyLoss : 0.0891. Training accuracy_score : 0.9658, Validation accuracy_score : 0.9655, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.966\n",
      "----------------------------------\n",
      "Running model without real_period..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 96 with Training CrossEntropyLoss : 0.6349, Validation CrossEntropyLoss : 0.6340. Training accuracy_score : 0.6262, Validation accuracy_score : 0.6269, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.635\n",
      "----------------------------------\n",
      "Running model without regulator..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 96 with Training CrossEntropyLoss : 0.0668, Validation CrossEntropyLoss : 0.0633. Training accuracy_score : 0.9677, Validation accuracy_score : 0.9675, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.967\n",
      "----------------------------------\n",
      "Running model without tamagawa_product..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 89 with Training CrossEntropyLoss : 0.2811, Validation CrossEntropyLoss : 0.2779. Training accuracy_score : 0.8279, Validation accuracy_score : 0.8297, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.826\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Neural Net classifier\n",
    "\n",
    "# choose model parameters\n",
    "hidden_units = [128,64,32]\n",
    "\n",
    "# check if we have cuda available\n",
    "device = 'cuda'\n",
    "\n",
    "# Map labels to range starting from 0\n",
    "df_BSD_label_mapped = df_balanced_bsd.copy()\n",
    "\n",
    "# Neural net training for binary classification expects labels to start at 0\n",
    "df_BSD_label_mapped['sha'] = df_BSD_label_mapped['sha'].map({4: 0, 9: 1})\n",
    "\n",
    "# choose training parameters\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "evaluator = accuracy_score\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results_df_nn = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n",
    "\n",
    "for i in range(len(bsd_features)-1):\n",
    "    print(f'Running model without {bsd_features[i]}..')\n",
    "    df_sub = df_BSD_label_mapped.drop(columns=[bsd_features[i]])\n",
    "    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sha', if_regression=False)\n",
    "    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n",
    "    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sha', device, if_regression=False, random_state=seed)\n",
    "    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n",
    "    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n",
    "    print(f\"Test accuracy: {acc:0.3f}\")\n",
    "    print('----------------------------------')\n",
    "    \n",
    "   # Append the results to the DataFrame\n",
    "    results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a0f4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature Deleted  Accuracy\n",
      "0     special_value  0.704739\n",
      "1           torsion  0.966389\n",
      "2       real_period  0.635237\n",
      "3         regulator  0.967034\n",
      "4  tamagawa_product  0.825550\n"
     ]
    }
   ],
   "source": [
    "print(results_df_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3. Delete one feature at a time on log-transformed data\n",
    "Accuracy is almost at 99% when removing either the size of torsion or the regulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d386",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model without special_value..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 64 with Training CrossEntropyLoss : 0.5403, Validation CrossEntropyLoss : 0.5451. Training accuracy_score : 0.7125, Validation accuracy_score : 0.7089, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.709\n",
      "----------------------------------\n",
      "Running model without torsion..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1103/14240141.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df_nn_log = pd.concat([results_df_nn_log, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 8 with Training CrossEntropyLoss : 0.0449, Validation CrossEntropyLoss : 0.0406. Training accuracy_score : 0.9886, Validation accuracy_score : 0.9898, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.990\n",
      "----------------------------------\n",
      "Running model without real_period..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 57 with Training CrossEntropyLoss : 0.6333, Validation CrossEntropyLoss : 0.6325. Training accuracy_score : 0.6320, Validation accuracy_score : 0.6283, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.637\n",
      "----------------------------------\n",
      "Running model without regulator..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 99 with Training CrossEntropyLoss : 0.0288, Validation CrossEntropyLoss : 0.0270. Training accuracy_score : 0.9895, Validation accuracy_score : 0.9904, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.988\n",
      "----------------------------------\n",
      "Running model without tamagawa_product..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 98 with Training CrossEntropyLoss : 0.2418, Validation CrossEntropyLoss : 0.2171. Training accuracy_score : 0.9121, Validation accuracy_score : 0.9129, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.911\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Neural Net classifier on log-transformed data\n",
    "\n",
    "# choose model parameters\n",
    "hidden_units = [128,64,32]\n",
    "\n",
    "# check if we have cuda available\n",
    "device = 'cuda'\n",
    "\n",
    "# Map labels to range starting from 0\n",
    "df_BSD_label_mapped = df_balanced_bsd.copy()\n",
    "for col in bsd_features[:-1]:\n",
    "    df_BSD_label_mapped[col]=df_BSD_label_mapped[col].apply(np.log)\n",
    "\n",
    "# Neural net training for binary classification expects labels to start at 0\n",
    "df_BSD_label_mapped['sha'] = df_BSD_label_mapped['sha'].map({4: 0, 9: 1})\n",
    "\n",
    "# choose training parameters\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "evaluator = accuracy_score\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results_df_nn_log = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n",
    "\n",
    "for i in range(len(bsd_features)-1):\n",
    "    print(f'Running model without {bsd_features[i]}..')\n",
    "    df_sub = df_BSD_label_mapped.drop(columns=[bsd_features[i]])\n",
    "    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sha', if_regression=False)\n",
    "    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n",
    "    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sha', device, if_regression=False, random_state=seed)\n",
    "    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n",
    "    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n",
    "    print(f\"Test accuracy: {acc:0.3f}\")\n",
    "    print('----------------------------------')\n",
    "    \n",
    "   # Append the results to the DataFrame\n",
    "    results_df_nn_log = pd.concat([results_df_nn_log, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba356",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature Deleted  Accuracy\n",
      "0     special_value  0.708804\n",
      "1           torsion  0.989639\n",
      "2       real_period  0.636823\n",
      "3         regulator  0.987904\n",
      "4  tamagawa_product  0.910817\n"
     ]
    }
   ],
   "source": [
    "print(results_df_nn_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "6111cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "1ba1c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "sage",
    "--python",
    "-m",
    "ipykernel",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "--matplotlib=inline",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (SageMath)",
   "env": {
   },
   "language": "python",
   "name": "python3-sage",
   "resource_dir": "/opt/venv/share/jupyter/kernels/python3-sage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}