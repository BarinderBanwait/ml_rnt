{"backend_state":"running","connection_file":"/projects/bda83a78-8667-461e-b29a-519419abf9c8/.local/share/jupyter/runtime/kernel-69adf83a-e0eb-4b68-bc14-17f3ad76e1a1.json","kernel":"python3-sage","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_ipynb_save":1734136979721,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"1ba1c9","input":"","pos":11,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"6111cf","input":"","pos":10,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":1,"id":"bc8479","input":"from lib import utils, models, executor\nimport torch.nn as nn\nimport torch.optim as optim\nfrom pathlib import Path\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# fix the seed for reproducibility\nseed = 42","pos":0,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":10,"id":"a2d386","input":"# Neural Net classifier on log-transformed data\n\n# choose model parameters\nhidden_units = [128,64,32]\n\n# check if we have cuda available\ndevice = 'cuda'\n\n# Map labels to range starting from 0\ndf_BSD_label_mapped = df_balanced_bsd.copy()\nfor col in bsd_features[:-1]:\n    df_BSD_label_mapped[col]=df_BSD_label_mapped[col].apply(np.log)\n\n# Neural net training for binary classification expects labels to start at 0\ndf_BSD_label_mapped['sha'] = df_BSD_label_mapped['sha'].map({4: 0, 9: 1})\n\n# choose training parameters\nloss_func = nn.CrossEntropyLoss()\nnum_epochs = 100\nlr = 0.001\nevaluator = accuracy_score\n\n# Initialize an empty DataFrame to store the results\nresults_df_nn_log = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n\nfor i in range(len(bsd_features)-1):\n    print(f'Running model without {bsd_features[i]}..')\n    df_sub = df_BSD_label_mapped.drop(columns=[bsd_features[i]])\n    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sha', if_regression=False)\n    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sha', device, if_regression=False, random_state=seed)\n    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n    print(f\"Test accuracy: {acc:0.3f}\")\n    print('----------------------------------')\n    \n   # Append the results to the DataFrame\n    results_df_nn_log = pd.concat([results_df_nn_log, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)","output":{"0":{"name":"stdout","output_type":"stream","text":"Running model without special_value..\nThe input dimension is 4 and the output dimension is 2.\n"},"1":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 64 with Training CrossEntropyLoss : 0.5403, Validation CrossEntropyLoss : 0.5451. Training accuracy_score : 0.7125, Validation accuracy_score : 0.7089, to ../trained_models/model.pth.\nTest accuracy: 0.709\n----------------------------------\nRunning model without torsion..\nThe input dimension is 4 and the output dimension is 2.\n"},"2":{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_1103/14240141.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df_nn_log = pd.concat([results_df_nn_log, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)\n"},"3":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 8 with Training CrossEntropyLoss : 0.0449, Validation CrossEntropyLoss : 0.0406. Training accuracy_score : 0.9886, Validation accuracy_score : 0.9898, to ../trained_models/model.pth.\nTest accuracy: 0.990\n----------------------------------\nRunning model without real_period..\nThe input dimension is 4 and the output dimension is 2.\n"},"4":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 57 with Training CrossEntropyLoss : 0.6333, Validation CrossEntropyLoss : 0.6325. Training accuracy_score : 0.6320, Validation accuracy_score : 0.6283, to ../trained_models/model.pth.\nTest accuracy: 0.637\n----------------------------------\nRunning model without regulator..\nThe input dimension is 4 and the output dimension is 2.\n"},"5":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 99 with Training CrossEntropyLoss : 0.0288, Validation CrossEntropyLoss : 0.0270. Training accuracy_score : 0.9895, Validation accuracy_score : 0.9904, to ../trained_models/model.pth.\nTest accuracy: 0.988\n----------------------------------\nRunning model without tamagawa_product..\nThe input dimension is 4 and the output dimension is 2.\n"},"6":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 98 with Training CrossEntropyLoss : 0.2418, Validation CrossEntropyLoss : 0.2171. Training accuracy_score : 0.9121, Validation accuracy_score : 0.9129, to ../trained_models/model.pth.\nTest accuracy: 0.911\n----------------------------------\n"}},"pos":8,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":11,"id":"0ba356","input":"print(results_df_nn_log)","output":{"0":{"name":"stdout","output_type":"stream","text":"    Feature Deleted  Accuracy\n0     special_value  0.708804\n1           torsion  0.989639\n2       real_period  0.636823\n3         regulator  0.987904\n4  tamagawa_product  0.910817\n"}},"pos":9,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":2,"id":"50274b","input":"# load your data here. The following ensure this will work on Windows as well as Unix\npath = Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000_reg.parquet\"\ndf = utils.load_data(path)","output":{"0":{"name":"stdout","output_type":"stream","text":"Loaded the dataset with 120 features and 3064705 curves..\n"}},"pos":1,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":3,"id":"d57fb4","input":"len_9 = df[df['sha'] == 9].shape[0]\ndf_balanced = df[df['sha'] == 4].sample(len_9, random_state=seed) \ndf_balanced = pd.concat([df_balanced, df[df['sha'] == 9]])\ndf_balanced.sha.value_counts()","output":{"0":{"data":{"text/plain":"sha\n4    50428\n9    50428\nName: count, dtype: int64"},"exec_count":3,"output_type":"execute_result"}},"pos":2,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"f3a706","input":"#Get columns with all the BSD features, from which we will eventually remove one at a time\nbsd_features = ['special_value', 'torsion', 'real_period', 'regulator', 'tamagawa_product', 'sha']\n\ndf_balanced_bsd = df_balanced[bsd_features].copy()","pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":5,"id":"01e4fc","input":"df_balanced_bsd.head(5)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>special_value</th>\n      <th>torsion</th>\n      <th>real_period</th>\n      <th>regulator</th>\n      <th>tamagawa_product</th>\n      <th>sha</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>334625</th>\n      <td>2.19751</td>\n      <td>2</td>\n      <td>0.54938</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1086182</th>\n      <td>3.22805</td>\n      <td>1</td>\n      <td>0.80701</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1782926</th>\n      <td>3.98612</td>\n      <td>2</td>\n      <td>0.49826</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2484030</th>\n      <td>2.99537</td>\n      <td>1</td>\n      <td>0.09361</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3053287</th>\n      <td>2.23394</td>\n      <td>1</td>\n      <td>0.09308</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"         special_value  torsion  real_period  regulator  tamagawa_product  sha\n334625         2.19751        2      0.54938        1.0                 4    4\n1086182        3.22805        1      0.80701        1.0                 1    4\n1782926        3.98612        2      0.49826        1.0                 8    4\n2484030        2.99537        1      0.09361        1.0                 8    4\n3053287        2.23394        1      0.09308        1.0                 6    4"},"exec_count":5,"output_type":"execute_result"}},"pos":4,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":6,"id":"394d4a","input":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","pos":5,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":7,"id":"07264c","input":"# Neural Net classifier\n\n# choose model parameters\nhidden_units = [128,64,32]\n\n# check if we have cuda available\ndevice = 'cuda'\n\n# Map labels to range starting from 0\ndf_BSD_label_mapped = df_balanced_bsd.copy()\n\n# Neural net training for binary classification expects labels to start at 0\ndf_BSD_label_mapped['sha'] = df_BSD_label_mapped['sha'].map({4: 0, 9: 1})\n\n# choose training parameters\nloss_func = nn.CrossEntropyLoss()\nnum_epochs = 100\nlr = 0.001\nevaluator = accuracy_score\n\n# Initialize an empty DataFrame to store the results\nresults_df_nn = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n\nfor i in range(len(bsd_features)-1):\n    print(f'Running model without {bsd_features[i]}..')\n    df_sub = df_BSD_label_mapped.drop(columns=[bsd_features[i]])\n    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sha', if_regression=False)\n    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sha', device, if_regression=False, random_state=seed)\n    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n    print(f\"Test accuracy: {acc:0.3f}\")\n    print('----------------------------------')\n    \n   # Append the results to the DataFrame\n    results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)","output":{"0":{"name":"stdout","output_type":"stream","text":"Running model without special_value..\nThe input dimension is 4 and the output dimension is 2.\n"},"1":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 89 with Training CrossEntropyLoss : 0.5473, Validation CrossEntropyLoss : 0.5517. Training accuracy_score : 0.7100, Validation accuracy_score : 0.7076, to ../trained_models/model.pth.\nTest accuracy: 0.705\n----------------------------------\nRunning model without torsion..\nThe input dimension is 4 and the output dimension is 2.\n"},"2":{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_1103/125803182.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)\n"},"3":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 80 with Training CrossEntropyLoss : 0.0953, Validation CrossEntropyLoss : 0.0891. Training accuracy_score : 0.9658, Validation accuracy_score : 0.9655, to ../trained_models/model.pth.\nTest accuracy: 0.966\n----------------------------------\nRunning model without real_period..\nThe input dimension is 4 and the output dimension is 2.\n"},"4":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 96 with Training CrossEntropyLoss : 0.6349, Validation CrossEntropyLoss : 0.6340. Training accuracy_score : 0.6262, Validation accuracy_score : 0.6269, to ../trained_models/model.pth.\nTest accuracy: 0.635\n----------------------------------\nRunning model without regulator..\nThe input dimension is 4 and the output dimension is 2.\n"},"5":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 96 with Training CrossEntropyLoss : 0.0668, Validation CrossEntropyLoss : 0.0633. Training accuracy_score : 0.9677, Validation accuracy_score : 0.9675, to ../trained_models/model.pth.\nTest accuracy: 0.967\n----------------------------------\nRunning model without tamagawa_product..\nThe input dimension is 4 and the output dimension is 2.\n"},"6":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 89 with Training CrossEntropyLoss : 0.2811, Validation CrossEntropyLoss : 0.2779. Training accuracy_score : 0.8279, Validation accuracy_score : 0.8297, to ../trained_models/model.pth.\nTest accuracy: 0.826\n----------------------------------\n"}},"pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":8,"id":"71a0f4","input":"print(results_df_nn)","output":{"0":{"name":"stdout","output_type":"stream","text":"    Feature Deleted  Accuracy\n0     special_value  0.704739\n1           torsion  0.966389\n2       real_period  0.635237\n3         regulator  0.967034\n4  tamagawa_product  0.825550\n"}},"pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","exec_count":3,"id":"ef96ff","input":"# 3. Delete one feature at a time on log-transformed data\nAccuracy is almost at 99% when removing either the size of torsion or the regulator.","kernel":"python3-sage","pos":7.5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"058b68","input":"# 2. Delete one feature at a time on original data\n\nThe best accuracy is about 97% when removing either the size of torsion or the regulator.","pos":4.5,"type":"cell"}
{"cell_type":"markdown","id":"307774","input":"This notebook is for a neural network (NN) on curves with size of Sha equal to 4 and 9 and removing one BSD feature at a time. This includes both the original and log-transformed data.","pos":-1,"type":"cell"}
{"cell_type":"markdown","id":"398f32","input":"# 1. Create balanced dataset of elliptic curves with size of the Tate-Shafarevich group equal to 4 and 9 containing all BSD features","pos":0.5,"type":"cell"}
{"id":0,"time":1734134354637,"type":"user"}
{"last_load":1734062837716,"type":"file"}