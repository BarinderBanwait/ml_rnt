{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "5acc6b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c9c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "8acab6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# fix the random seed\n",
    "seed = 42\n",
    "\n",
    "# load the small conductor dataset here\n",
    "path = '../data_files/sha/ecq_sha_B_100_conds_1_500000_reg.parquet'\n",
    "columns = ['rank', 'regulator', 'torsion', 'sha', 'special_value', 'real_period', 'tamagawa_product']\n",
    "\n",
    "# Read the specified columns using PyArrow\n",
    "table = pq.read_table(path, columns=columns)\n",
    "# Convert the PyArrow Table to a Pandas DataFrame\n",
    "df = table.to_pandas()\n",
    "\n",
    "# sqrt sha\n",
    "df['sqrt_sha'] = df['sha'].apply(lambda x: int(x**0.5))\n",
    "df.drop('sha', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf93",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Options for imbalanced dataset\n",
    "- Option 1: downsize the majority class (sha trivial curves) \n",
    "- Option 2: upsize the minority class (sha nontrivial curves) \n",
    "- default is False to both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "9033ae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "downsizing = False\n",
    "upsizing = False\n",
    "\n",
    "majority_ratio = 0.6\n",
    "majority_ratio = 0.5\n",
    "\n",
    "if downsizing == True:\n",
    "    df_majority = df[df['sqrt_sha'] == 1]  # Filter out rows with sha == 1\n",
    "    df_minority = df[df['sqrt_sha'] != 1]  # Filter out rows with sha != 1\n",
    "    # Calculate the number of samples needed to make sha == 1 roughly 70% of the data\n",
    "    target_majority_count = int(len(df_minority) / (1-majority_ratio) * majority_ratio)\n",
    "    # Randomly sample the majority class to reduce it to the target count\n",
    "    df_majority_downsampled = df_majority.sample(target_majority_count, random_state=seed)\n",
    "    # Combine the downsampled majority class with the minority class\n",
    "    df = pd.concat([df_majority_downsampled, df_minority])\n",
    "    # Shuffle the resulting DataFrame to mix the rows\n",
    "    df = df.sample(frac=1, random_state=seed).reset_index(drop=True)   \n",
    "elif upsizing == True:\n",
    "    minority_class = df[df['sqrt_sha'] > 1]\n",
    "    majority_class = df[df['sqrt_sha'] == 1]\n",
    "    # Resample the minority class\n",
    "    minority_upsampled = resample(minority_class, replace=True, n_samples=int(len(majority_class)/majority_ratio*(1-majority_ratio)), random_state=seed)\n",
    "    # Combine the upsampled minority class with the majority class\n",
    "    df = pd.concat([majority_class, minority_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f947f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train with conductor < 500k curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "3da767",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Run a tree regression model with rank and no regulator\n",
    "# model is called model_w_rank\n",
    "\n",
    "# Prepare the data\n",
    "feature_columns = [c for c in df.columns if c != 'sqrt_sha']\n",
    "feature_columns_no_reg = feature_columns.copy()\n",
    "feature_columns_no_reg.remove('regulator')\n",
    "X = df[feature_columns_no_reg]\n",
    "y = df[['sqrt_sha']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Train the model\n",
    "model_w_rank = HistGradientBoostingRegressor(random_state=seed)\n",
    "model_w_rank.fit(X_train, y_train)\n",
    "y_pred = model_w_rank.predict(X_test)\n",
    "y_pred_rounded_w_rank = np.round(y_pred).astype(int)\n",
    "\n",
    "# # Convert y_test to a 1D list of actual values\n",
    "y_test = y_test.values.flatten()\n",
    "\n",
    "# Calculate accuracy\n",
    "w_rank_accuracy = accuracy_score(y_pred_rounded_w_rank, y_test)\n",
    "\n",
    "# calculate MCC\n",
    "w_rank_MCC = matthews_corrcoef(y_test, y_pred_rounded_w_rank)\n",
    "\n",
    "# get the unique predicted values \n",
    "y_test_less_500_unique = np.unique(y_test)\n",
    "y_pred_less_500_unique_w_rank = np.unique(y_pred_rounded_w_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "6f678a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Run a tree-based regressor without rank or regulator\n",
    "# model is called model_wo\n",
    "\n",
    "# Prepare the data\n",
    "feature_columns_no_rank = feature_columns.copy()\n",
    "feature_columns_no_rank.remove('rank')\n",
    "feature_columns_no_rank.remove('regulator')\n",
    "X = df[feature_columns_no_rank]\n",
    "y = df[['sqrt_sha']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Train the model\n",
    "model_wo = HistGradientBoostingRegressor(random_state=seed)\n",
    "model_wo.fit(X_train, y_train)\n",
    "y_pred = model_wo.predict(X_test)\n",
    "y_pred_rounded_wo = np.round(y_pred).astype(int)\n",
    "\n",
    "# # Convert y_test to a 1D list of actual values\n",
    "y_test = y_test.values.flatten()\n",
    "\n",
    "# Calculate accuracy\n",
    "wo_accuracy = accuracy_score(y_pred_rounded_wo, y_test)\n",
    "\n",
    "# calculate MCC\n",
    "wo_MCC = matthews_corrcoef(y_test, y_pred_rounded_wo)\n",
    "\n",
    "# get unique predicted values\n",
    "y_pred_less_500_unique_wo = np.unique(y_pred_rounded_wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "1f757b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Run a tree-based regressor without rank but with regulator\n",
    "# model is called model_w_reg\n",
    "\n",
    "# Prepare the data\n",
    "feature_columns_no_rank = feature_columns.copy()\n",
    "feature_columns_no_rank.remove('rank')\n",
    "X = df[feature_columns_no_rank]\n",
    "y = df[['sqrt_sha']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Train the model\n",
    "model_w_reg = HistGradientBoostingRegressor(random_state=seed)\n",
    "model_w_reg.fit(X_train, y_train)\n",
    "y_pred = model_w_reg.predict(X_test)\n",
    "y_pred_rounded_w_reg = np.round(y_pred).astype(int)\n",
    "\n",
    "# # Convert y_test to a 1D list of actual values\n",
    "y_test = y_test.values.flatten()\n",
    "\n",
    "# Calculate accuracy\n",
    "w_reg_accuracy = accuracy_score(y_pred_rounded_w_reg, y_test)\n",
    "\n",
    "# calculate MCC\n",
    "w_reg_MCC = matthews_corrcoef(y_test, y_pred_rounded_w_reg)\n",
    "\n",
    "# get unique predicted values\n",
    "y_pred_less_500_unique_w_reg = np.unique(y_pred_rounded_w_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "0e0ec7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# print the results\n",
    "print('cond less than 500k curves: ')\n",
    "print(f'unique sha values: {y_test_less_500_unique}')\n",
    "print('-'*10)\n",
    "print(f'Features with rank but no regulator gives acc: ', w_rank_accuracy)\n",
    "print(f'Features without rank or regulator gives acc: ', wo_accuracy)\n",
    "print(f'Features with regulator but no rank gives acc: ', w_reg_accuracy)\n",
    "print('-'*10)\n",
    "print(f'Features with rank but no regulator gives MCC: ', w_rank_MCC)\n",
    "print(f'Features without rank or regulator gives MCC: ', wo_MCC)\n",
    "print(f'Features with regulator but no rank gives MCC: ', w_reg_MCC)\n",
    "print('-'*10)\n",
    "print(f'unique pred values with rank but no regulator: {y_pred_less_500_unique_w_rank}')\n",
    "print(f'unique pred values without rank or regulator: {y_pred_less_500_unique_wo}')\n",
    "print(f'unique pred values with regulator but no rank: {y_pred_less_500_unique_w_reg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "20e407",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# check acc when sqrt > threshold \n",
    "threshold_acc = []\n",
    "min_threshold = 1 # min threshold\n",
    "max_threshold = 8 # max threshold\n",
    "\n",
    "for threshold in range(min_threshold,max_threshold):\n",
    "    y_test_gt_threshold_where = np.where(y_test >= threshold)\n",
    "    y_test_gt_threshold = y_test[y_test_gt_threshold_where]\n",
    "    y_pred_rounded_gt_threshold_w_rank = y_pred_rounded_w_rank[y_test_gt_threshold_where]\n",
    "    y_pred_rounded_gt_threshold_wo = y_pred_rounded_wo[y_test_gt_threshold_where]\n",
    "    y_pred_rounded_gt_threshold_w_reg = y_pred_rounded_w_reg[y_test_gt_threshold_where]\n",
    "    threshold_acc.append([threshold, accuracy_score(y_pred_rounded_gt_threshold_w_rank, y_test_gt_threshold), accuracy_score(y_pred_rounded_gt_threshold_wo, y_test_gt_threshold), accuracy_score(y_pred_rounded_gt_threshold_w_reg, y_test_gt_threshold), len(y_test_gt_threshold)])\n",
    "    \n",
    "threshold_acc = pd.DataFrame(threshold_acc,index=[f'sqrt_sha (sha >= {i})' for i in range(min_threshold,max_threshold)],columns=['Threshold','with rank no reg','without rank or reg', 'with reg no rank', 'num of curves'])\n",
    "threshold_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "05befa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# plot threshold_acc\n",
    "threshold_acc.drop(columns=['num of curves'],inplace=True)\n",
    "threshold_acc = threshold_acc.melt(id_vars=\"Threshold\", var_name=\"Features Type\", value_name=\"Accuracy\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Threshold\", y=\"Accuracy\", hue=\"Features Type\", data=threshold_acc)\n",
    "\n",
    "# Labeling\n",
    "plt.xlabel(\"Sqrt Sha Threshold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Small Conductor Dataset Accuracy\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d16e8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test with >500k curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "99f26d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "path = '../data_files/sha/ecq_sha_B_1000_conds_lt_500k.parquet'\n",
    "\n",
    "# Read the specified columns using PyArrow\n",
    "table = pq.read_table(path, columns=columns)\n",
    "# Convert the PyArrow Table to a Pandas DataFrame\n",
    "df_large_cond = table.to_pandas()\n",
    "\n",
    "# sqrt sha\n",
    "df_large_cond['sqrt_sha'] = df_large_cond['sha'].apply(lambda x: int(x**0.5))\n",
    "df_large_cond.drop('sha', axis=1, inplace=True)\n",
    "\n",
    "# Prepare the data\n",
    "label_col = 'sqrt_sha'\n",
    "X_test_large_cond = df_large_cond.drop(columns=[label_col])\n",
    "y_test_large_cond = df_large_cond[label_col].values\n",
    "\n",
    "# Run the models on the large conductor dataset\n",
    "# model_w_rank\n",
    "X_test_large_cond_no_reg = X_test_large_cond.drop(columns = ['regulator'])\n",
    "y_pred = model_w_rank.predict(X_test_large_cond_no_reg)\n",
    "y_pred_w_rank = np.round(y_pred).astype(int)\n",
    "y_pred_more_500_unique_w_rank = np.unique(y_pred_w_rank)\n",
    "\n",
    "# model_wo\n",
    "X_test_large_cond_no_reg.drop(columns = ['rank'],inplace=True)\n",
    "y_pred = model_wo.predict(X_test_large_cond_no_reg)\n",
    "y_pred_wo = np.round(y_pred).astype(int)\n",
    "y_pred_more_500_unique_wo = np.unique(y_pred_wo)\n",
    "\n",
    "# model_w_reg\n",
    "X_test_large_cond.drop(columns = ['rank'],inplace = True)\n",
    "y_pred = model_w_reg.predict(X_test_large_cond)\n",
    "y_pred_w_reg = np.round(y_pred).astype(int)\n",
    "y_pred_more_500_unique_w_reg = np.unique(y_pred_w_reg)\n",
    "\n",
    "# # Convert y_test to a 1D list of actual values\n",
    "y_test_large_cond = y_test_large_cond.flatten()\n",
    "\n",
    "# Calculate accuracy\n",
    "w_rank_accuracy = accuracy_score(y_test_large_cond, y_pred_w_rank)\n",
    "wo_accuracy = accuracy_score(y_test_large_cond, y_pred_wo)\n",
    "w_reg_accuracy = accuracy_score(y_test_large_cond, y_pred_w_reg)\n",
    "\n",
    "# Calculate MCC\n",
    "w_rank_MCC = matthews_corrcoef(y_test_large_cond, y_pred_w_rank)\n",
    "wo_MCC = matthews_corrcoef(y_test_large_cond, y_pred_wo)\n",
    "w_reg_MCC = matthews_corrcoef(y_test_large_cond, y_pred_w_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "53c3ca",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print('cond more than 500k curves: ')\n",
    "print(f'unique sha values: {np.unique(y_test_large_cond)}')\n",
    "print('-'*10)\n",
    "print(f'Features with rank but no regulator: gives acc: ', w_rank_accuracy)\n",
    "print(f'Features without rank or regulator: gives acc: ', wo_accuracy)\n",
    "print(f'Features with regulator but no rank: gives acc: ', w_reg_accuracy)\n",
    "print('-'*10)\n",
    "print(f'Features with rank but no regulator: gives MCC: ', w_rank_MCC)\n",
    "print(f'Features without rank or regulator: gives MCC: ', wo_MCC)\n",
    "print(f'Features with regulator but no rank: gives MCC: ', w_reg_MCC)\n",
    "print('-'*10)\n",
    "print(f'unique pred values with rank but no regulator: {y_pred_more_500_unique_w_rank}')\n",
    "print(f'unique pred values without rank or regulator: {y_pred_more_500_unique_wo}')\n",
    "print(f'unique pred values with regulator but no rank: {y_pred_more_500_unique_w_reg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "65e246",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# check acc when sqrt > threshold\n",
    "threshold_acc = []\n",
    "\n",
    "for threshold in range(1,8):\n",
    "    y_test_large_cond_gt_threshold_where = np.where(y_test_large_cond >= threshold)[0]\n",
    "    y_test_large_cond_gt_threshold = y_test_large_cond[y_test_large_cond_gt_threshold_where]\n",
    "    \n",
    "    y_pred_w_rank_gt_threshold = y_pred_w_rank[y_test_large_cond_gt_threshold_where]\n",
    "    y_pred_wo_gt_threshold = y_pred_wo[y_test_large_cond_gt_threshold_where]\n",
    "    y_pred_w_reg_gt_threshold = y_pred_w_reg[y_test_large_cond_gt_threshold_where]\n",
    "    \n",
    "    threshold_acc.append([threshold, accuracy_score(y_pred_w_rank_gt_threshold, y_test_large_cond_gt_threshold), accuracy_score(y_pred_wo_gt_threshold, y_test_large_cond_gt_threshold) , accuracy_score(y_pred_w_reg_gt_threshold, y_test_large_cond_gt_threshold), len(y_test_large_cond_gt_threshold_where)])\n",
    "    \n",
    "threshold_acc = pd.DataFrame(threshold_acc,index=[f'acc (sqrt_sha >= {i})' for i in range(1,8)],columns=['Threshold','with rank no reg','without rank or reg', 'with reg no rank', 'num of curves'])\n",
    "threshold_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "0996cc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# plot threshold_acc\n",
    "threshold_acc.drop(columns=['num of curves'],inplace=True)\n",
    "threshold_acc = threshold_acc.melt(id_vars=\"Threshold\", var_name=\"Features Type\", value_name=\"Accuracy\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Threshold\", y=\"Accuracy\", hue=\"Features Type\", data=threshold_acc)\n",
    "\n",
    "# Labeling\n",
    "plt.xlabel(\"Sqrt Sha Threshold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Large Conductor Dataset Accuracy\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c91",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Appendix: plotting curves with trivial sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "cbcbfe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# for small conductor dataset\n",
    "\n",
    "rank0_proportion = []\n",
    "for i in range(len(df['sqrt_sha'].unique())+1):\n",
    "    df_gt = df[df['sqrt_sha'] >= i]\n",
    "    rank0_proportion.append(len(df_gt[df_gt['rank'] == 0])/len(df_gt) * 100)\n",
    "    \n",
    "# plot the proportion of rank 0 curves as a function of sqrt_sha using seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(x=range(len(df['sqrt_sha'].unique())+1), y=rank0_proportion)\n",
    "plt.xlabel('lower bound of sqrt_sha')\n",
    "plt.ylabel('Proportion of rank 0 curves (%)')\n",
    "plt.title('Proportion of rank 0 curves (%) in the small conductor dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "dc4d80",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# for big conductor dataset\n",
    "\n",
    "rank0_proportion = []\n",
    "for i in range(len(df_large_cond['sqrt_sha'].unique())+1):\n",
    "    df_gt = df_large_cond[df_large_cond['sqrt_sha'] >= i]\n",
    "    rank0_proportion.append(len(df_gt[df_gt['rank'] == 0])/len(df_gt) * 100)\n",
    "    \n",
    "# plot the proportion of rank 0 curves as a function of sqrt_sha using seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(x=range(len(df_large_cond['sqrt_sha'].unique())+1), y=rank0_proportion)\n",
    "plt.xlabel('sqrt_sha threshold')\n",
    "plt.ylabel('Proportion of rank 0 curves (%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "sage",
    "--python",
    "-m",
    "ipykernel",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "--matplotlib=inline",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (SageMath)",
   "env": {
   },
   "language": "python",
   "name": "python3-sage",
   "resource_dir": "/opt/venv/share/jupyter/kernels/python3-sage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}