{"backend_state":"ready","kernel":"python3-sage","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_ipynb_save":1734133785726,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"1ba1c9","input":"","pos":11,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"6111cf","input":"","pos":10,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":1,"id":"bc8479","input":"from lib import utils, models, executor\nimport torch.nn as nn\nimport torch.optim as optim\nfrom pathlib import Path\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# fix the seed for reproducibility\nseed = 42","pos":0,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":10,"id":"0ba356","input":"print(results_df_nn_log)","output":{"0":{"name":"stdout","output_type":"stream","text":"    Feature Deleted  Accuracy\n0     special_value  0.922234\n1           torsion  0.818413\n2       real_period  0.778193\n3         regulator  0.826697\n4  tamagawa_product  0.772582\n"}},"pos":9,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":2,"id":"50274b","input":"# load your data here. The following ensure this will work on Windows as well as Unix\npath = Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000_reg.parquet\"\ndf = utils.load_data(path)\ndf=df[df['rank']>0]","output":{"0":{"name":"stdout","output_type":"stream","text":"Loaded the dataset with 120 features and 3064705 curves..\n"}},"pos":1,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":3,"id":"d57fb4","input":"len_4 = df[df['sha'] == 4].shape[0]\ndf_balanced = df[df['sha'] == 1].sample(len_4, random_state=seed) \ndf_balanced = pd.concat([df_balanced, df[df['sha'] == 4]])\ndf_balanced.sha.value_counts()","output":{"0":{"data":{"text/plain":"sha\n1    18710\n4    18710\nName: count, dtype: int64"},"exec_count":3,"output_type":"execute_result"}},"pos":2,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"f3a706","input":"#Get columns with all the BSD features, from which we will eventually remove one at a time\nbsd_features = ['special_value', 'torsion', 'real_period', 'regulator', 'tamagawa_product', 'sha']\n\ndf_balanced_bsd = df_balanced[bsd_features].copy()","pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":5,"id":"01e4fc","input":"df_balanced_bsd.head(5)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>special_value</th>\n      <th>torsion</th>\n      <th>real_period</th>\n      <th>regulator</th>\n      <th>tamagawa_product</th>\n      <th>sha</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>393967</th>\n      <td>7.08730</td>\n      <td>4</td>\n      <td>0.87493</td>\n      <td>8.10043</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>811492</th>\n      <td>5.28675</td>\n      <td>2</td>\n      <td>0.31006</td>\n      <td>1.70505</td>\n      <td>40</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>872987</th>\n      <td>9.43579</td>\n      <td>1</td>\n      <td>1.05987</td>\n      <td>2.22569</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>761927</th>\n      <td>2.52192</td>\n      <td>2</td>\n      <td>0.54553</td>\n      <td>0.57786</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2647019</th>\n      <td>5.41466</td>\n      <td>1</td>\n      <td>0.31870</td>\n      <td>4.24740</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"         special_value  torsion  real_period  regulator  tamagawa_product  sha\n393967         7.08730        4      0.87493    8.10043                16    1\n811492         5.28675        2      0.31006    1.70505                40    1\n872987         9.43579        1      1.05987    2.22569                 4    1\n761927         2.52192        2      0.54553    0.57786                32    1\n2647019        5.41466        1      0.31870    4.24740                 4    1"},"exec_count":5,"output_type":"execute_result"}},"pos":4,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":6,"id":"394d4a","input":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","pos":5,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":7,"id":"07264c","input":"# Neural Net classifier\n\n# choose model parameters\nhidden_units = [128,64,32]\n\n# check if we have cuda available\ndevice = 'cuda'\n\n# Map labels to range starting from 0\ndf_BSD_label_mapped = df_balanced_bsd.copy()\n\n# Neural net training for binary classification expects labels to start at 0\ndf_BSD_label_mapped['sha'] = df_BSD_label_mapped['sha'].map({1: 0, 4: 1})\n\n# choose training parameters\nloss_func = nn.CrossEntropyLoss()\nnum_epochs = 100\nlr = 0.001\nevaluator = accuracy_score\n\n# Initialize an empty DataFrame to store the results\nresults_df_nn = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n\nfor i in range(len(bsd_features)-1):\n    print(f'Running model without {bsd_features[i]}..')\n    df_sub = df_BSD_label_mapped.drop(columns=[bsd_features[i]])\n    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sha', if_regression=False)\n    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sha', device, if_regression=False, random_state=seed)\n    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n    print(f\"Test accuracy: {acc:0.3f}\")\n    print('----------------------------------')\n    \n   # Append the results to the DataFrame\n    results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)","output":{"0":{"name":"stdout","output_type":"stream","text":"Running model without special_value..\nThe input dimension is 4 and the output dimension is 2.\n"},"1":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 79 with Training CrossEntropyLoss : 0.2059, Validation CrossEntropyLoss : 0.2112. Training accuracy_score : 0.8807, Validation accuracy_score : 0.8784, to ../trained_models/model.pth.\nTest accuracy: 0.885\n----------------------------------\nRunning model without torsion..\nThe input dimension is 4 and the output dimension is 2.\n"},"2":{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_1277/1887803710.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)\n"},"3":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 85 with Training CrossEntropyLoss : 0.4198, Validation CrossEntropyLoss : 0.4357. Training accuracy_score : 0.8020, Validation accuracy_score : 0.7982, to ../trained_models/model.pth.\nTest accuracy: 0.799\n----------------------------------\nRunning model without real_period..\nThe input dimension is 4 and the output dimension is 2.\n"},"4":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 90 with Training CrossEntropyLoss : 0.4696, Validation CrossEntropyLoss : 0.4714. Training accuracy_score : 0.7798, Validation accuracy_score : 0.7805, to ../trained_models/model.pth.\nTest accuracy: 0.776\n----------------------------------\nRunning model without regulator..\nThe input dimension is 4 and the output dimension is 2.\n"},"5":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 79 with Training CrossEntropyLoss : 0.3897, Validation CrossEntropyLoss : 0.3962. Training accuracy_score : 0.8287, Validation accuracy_score : 0.8259, to ../trained_models/model.pth.\nTest accuracy: 0.823\n----------------------------------\nRunning model without tamagawa_product..\nThe input dimension is 4 and the output dimension is 2.\n"},"6":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 92 with Training CrossEntropyLoss : 0.4916, Validation CrossEntropyLoss : 0.5029. Training accuracy_score : 0.7684, Validation accuracy_score : 0.7642, to ../trained_models/model.pth.\nTest accuracy: 0.765\n----------------------------------\n"}},"pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":8,"id":"71a0f4","input":"print(results_df_nn)","output":{"0":{"name":"stdout","output_type":"stream","text":"    Feature Deleted  Accuracy\n0     special_value  0.884687\n1           torsion  0.799172\n2       real_period  0.776323\n3         regulator  0.822688\n4  tamagawa_product  0.765366\n"}},"pos":7,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":9,"id":"a2d386","input":"# Neural Net classifier on log-transformed data\n\n# choose model parameters\nhidden_units = [128,64,32]\n\n# check if we have cuda available\ndevice = 'cuda'\n\n# Map labels to range starting from 0\ndf_BSD_label_mapped = df_balanced_bsd.copy()\nfor col in bsd_features[:-1]:\n    df_BSD_label_mapped[col]=df_BSD_label_mapped[col].apply(np.log)\n\n# Neural net training for binary classification expects labels to start at 0\ndf_BSD_label_mapped['sha'] = df_BSD_label_mapped['sha'].map({1: 0, 4: 1})\n\n# choose training parameters\nloss_func = nn.CrossEntropyLoss()\nnum_epochs = 100\nlr = 0.001\nevaluator = accuracy_score\n\n# Initialize an empty DataFrame to store the results\nresults_df_nn_log = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n\nfor i in range(len(bsd_features)-1):\n    print(f'Running model without {bsd_features[i]}..')\n    df_sub = df_BSD_label_mapped.drop(columns=[bsd_features[i]])\n    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sha', if_regression=False)\n    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sha', device, if_regression=False, random_state=seed)\n    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n    print(f\"Test accuracy: {acc:0.3f}\")\n    print('----------------------------------')\n    \n   # Append the results to the DataFrame\n    results_df_nn_log = pd.concat([results_df_nn_log, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)","output":{"0":{"name":"stdout","output_type":"stream","text":"Running model without special_value..\nThe input dimension is 4 and the output dimension is 2.\n"},"1":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 21 with Training CrossEntropyLoss : 0.1895, Validation CrossEntropyLoss : 0.1884. Training accuracy_score : 0.9225, Validation accuracy_score : 0.9253, to ../trained_models/model.pth.\nTest accuracy: 0.922\n----------------------------------\nRunning model without torsion..\nThe input dimension is 4 and the output dimension is 2.\n"},"2":{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_1277/2569573343.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df_nn_log = pd.concat([results_df_nn_log, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)\n"},"3":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 91 with Training CrossEntropyLoss : 0.3967, Validation CrossEntropyLoss : 0.4151. Training accuracy_score : 0.8180, Validation accuracy_score : 0.8111, to ../trained_models/model.pth.\nTest accuracy: 0.818\n----------------------------------\nRunning model without real_period..\nThe input dimension is 4 and the output dimension is 2.\n"},"4":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 88 with Training CrossEntropyLoss : 0.4617, Validation CrossEntropyLoss : 0.4650. Training accuracy_score : 0.7821, Validation accuracy_score : 0.7827, to ../trained_models/model.pth.\nTest accuracy: 0.778\n----------------------------------\nRunning model without regulator..\nThe input dimension is 4 and the output dimension is 2.\n"},"5":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 83 with Training CrossEntropyLoss : 0.3831, Validation CrossEntropyLoss : 0.3917. Training accuracy_score : 0.8303, Validation accuracy_score : 0.8294, to ../trained_models/model.pth.\nTest accuracy: 0.827\n----------------------------------\nRunning model without tamagawa_product..\nThe input dimension is 4 and the output dimension is 2.\n"},"6":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 84 with Training CrossEntropyLoss : 0.4768, Validation CrossEntropyLoss : 0.4876. Training accuracy_score : 0.7746, Validation accuracy_score : 0.7687, to ../trained_models/model.pth.\nTest accuracy: 0.773\n----------------------------------\n"}},"pos":8,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"38e542","input":"# 2. Delete one feature at a time on original data\nThe best accuracy is about 88% when removing the special value.","pos":4.5,"type":"cell"}
{"cell_type":"markdown","id":"5fff38","input":"# 3. Delete one feature at a time on log-transformed data\n\nThe best accuracy is about 92% when removing the special value.","pos":7.5,"type":"cell"}
{"cell_type":"markdown","id":"73cd9d","input":"This notebook is for a neural network (NN) on curves with positive rank and size of Sha equal to 1 and 4 and removing one BSD feature at a time. This includes both the original and log-transformed data.","pos":-1,"type":"cell"}
{"cell_type":"markdown","id":"f4f0fc","input":"# 1. Create balanced dataset of elliptic curves with size of the Tate-Shafarevich group equal to 4 and 9 containing all BSD features","pos":0.5,"type":"cell"}
{"id":0,"time":1734133049380,"type":"user"}
{"last_load":1734063025241,"type":"file"}