{"backend_state":"ready","kernel":"python3-sage","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_ipynb_save":1734136979721,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"4da242","input":"","pos":9,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":1,"id":"b2bb97","input":"from lib import utils, models, executor\nimport torch.nn as nn\nimport torch.optim as optim\nfrom pathlib import Path\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# fix the seed for reproducibility\nseed = 42","pos":0,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":2,"id":"034c61","input":"# load your data here. The following ensure this will work on Windows as well as Unix\npath = Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000_reg.parquet\"\ndf = utils.load_data(path)","output":{"0":{"name":"stdout","output_type":"stream","text":"Loaded the dataset with 120 features and 3064705 curves..\n"}},"pos":1,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":3,"id":"0617df","input":"len_9 = df[df['sha'] == 9].shape[0]\ndf_balanced = df[df['sha'] == 4].sample(len_9, random_state=seed) \ndf_balanced = pd.concat([df_balanced, df[df['sha'] == 9]])\ndf_balanced.sha.value_counts()","output":{"0":{"data":{"text/plain":"sha\n4    50428\n9    50428\nName: count, dtype: int64"},"exec_count":3,"output_type":"execute_result"}},"pos":2,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"971806","input":"bsd_features = ['special_value', 'torsion', 'real_period', 'regulator', 'tamagawa_product', 'sha']\nprimes=['2', '3', '5', '7', '11', '13', '17', '19', '23', '29', '31', '37',\n       '41', '43', '47', '53', '59', '61', '67', '71', '73', '79', '83', '89',\n       '97', '101', '103', '107', '109', '113', '127', '131', '137', '139',\n       '149', '151', '157', '163', '167', '173', '179', '181', '191', '193',\n       '197', '199', '211', '223', '227', '229', '233', '239', '241', '251',\n       '257', '263', '269', '271', '277', '281', '283', '293', '307', '311',\n       '313', '317', '331', '337', '347', '349', '353', '359', '367', '373',\n       '379', '383', '389', '397', '401', '409', '419', '421', '431', '433',\n       '439', '443', '449', '457', '461', '463', '467', '479', '487', '491',\n       '499', '503', '509', '521', '523', '541']","pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":5,"id":"82d1bd","input":"df_balanced_bsd = df_balanced[bsd_features + primes].copy()","pos":4,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":6,"id":"ca90bc","input":"df_balanced_bsd.head(5)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>special_value</th>\n      <th>torsion</th>\n      <th>real_period</th>\n      <th>regulator</th>\n      <th>tamagawa_product</th>\n      <th>sha</th>\n      <th>2</th>\n      <th>3</th>\n      <th>5</th>\n      <th>7</th>\n      <th>...</th>\n      <th>467</th>\n      <th>479</th>\n      <th>487</th>\n      <th>491</th>\n      <th>499</th>\n      <th>503</th>\n      <th>509</th>\n      <th>521</th>\n      <th>523</th>\n      <th>541</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>334625</th>\n      <td>2.19751</td>\n      <td>2</td>\n      <td>0.54938</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0.35355</td>\n      <td>0.00000</td>\n      <td>-0.44721</td>\n      <td>0.18898</td>\n      <td>...</td>\n      <td>0.27765</td>\n      <td>0.18276</td>\n      <td>-0.18126</td>\n      <td>0.72207</td>\n      <td>0.08953</td>\n      <td>0.57964</td>\n      <td>0.44324</td>\n      <td>-0.13143</td>\n      <td>0.61218</td>\n      <td>0.47293</td>\n    </tr>\n    <tr>\n      <th>1086182</th>\n      <td>3.22805</td>\n      <td>1</td>\n      <td>0.80701</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.70711</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>-0.56695</td>\n      <td>...</td>\n      <td>0.18510</td>\n      <td>-0.15992</td>\n      <td>-0.54377</td>\n      <td>-0.04513</td>\n      <td>0.62673</td>\n      <td>0.66882</td>\n      <td>0.39892</td>\n      <td>-0.59145</td>\n      <td>-0.02186</td>\n      <td>-0.34395</td>\n    </tr>\n    <tr>\n      <th>1782926</th>\n      <td>3.98612</td>\n      <td>2</td>\n      <td>0.49826</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0.00000</td>\n      <td>0.57735</td>\n      <td>-0.44721</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>-0.50902</td>\n      <td>0.18276</td>\n      <td>0.09063</td>\n      <td>0.27078</td>\n      <td>-0.71626</td>\n      <td>-0.17835</td>\n      <td>0.66486</td>\n      <td>0.30668</td>\n      <td>0.34982</td>\n      <td>0.64490</td>\n    </tr>\n    <tr>\n      <th>2484030</th>\n      <td>2.99537</td>\n      <td>1</td>\n      <td>0.09361</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>4</td>\n      <td>-0.35355</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.18898</td>\n      <td>...</td>\n      <td>0.34706</td>\n      <td>0.68537</td>\n      <td>0.29454</td>\n      <td>0.11282</td>\n      <td>0.24621</td>\n      <td>0.31211</td>\n      <td>0.59838</td>\n      <td>-0.37239</td>\n      <td>0.48100</td>\n      <td>-0.81687</td>\n    </tr>\n    <tr>\n      <th>3053287</th>\n      <td>2.23394</td>\n      <td>1</td>\n      <td>0.09308</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>-0.35355</td>\n      <td>-0.28868</td>\n      <td>0.00000</td>\n      <td>0.94491</td>\n      <td>...</td>\n      <td>-0.83294</td>\n      <td>-0.13707</td>\n      <td>0.90629</td>\n      <td>0.18052</td>\n      <td>-0.62673</td>\n      <td>0.98093</td>\n      <td>0.17730</td>\n      <td>0.48192</td>\n      <td>0.89640</td>\n      <td>-0.17197</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 106 columns</p>\n</div>","text/plain":"         special_value  torsion  real_period  regulator  tamagawa_product  \\\n334625         2.19751        2      0.54938        1.0                 4   \n1086182        3.22805        1      0.80701        1.0                 1   \n1782926        3.98612        2      0.49826        1.0                 8   \n2484030        2.99537        1      0.09361        1.0                 8   \n3053287        2.23394        1      0.09308        1.0                 6   \n\n         sha        2        3        5        7  ...      467      479  \\\n334625     4  0.35355  0.00000 -0.44721  0.18898  ...  0.27765  0.18276   \n1086182    4  0.70711  0.00000  0.00000 -0.56695  ...  0.18510 -0.15992   \n1782926    4  0.00000  0.57735 -0.44721  0.00000  ... -0.50902  0.18276   \n2484030    4 -0.35355  0.00000  0.00000  0.18898  ...  0.34706  0.68537   \n3053287    4 -0.35355 -0.28868  0.00000  0.94491  ... -0.83294 -0.13707   \n\n             487      491      499      503      509      521      523  \\\n334625  -0.18126  0.72207  0.08953  0.57964  0.44324 -0.13143  0.61218   \n1086182 -0.54377 -0.04513  0.62673  0.66882  0.39892 -0.59145 -0.02186   \n1782926  0.09063  0.27078 -0.71626 -0.17835  0.66486  0.30668  0.34982   \n2484030  0.29454  0.11282  0.24621  0.31211  0.59838 -0.37239  0.48100   \n3053287  0.90629  0.18052 -0.62673  0.98093  0.17730  0.48192  0.89640   \n\n             541  \n334625   0.47293  \n1086182 -0.34395  \n1782926  0.64490  \n2484030 -0.81687  \n3053287 -0.17197  \n\n[5 rows x 106 columns]"},"exec_count":6,"output_type":"execute_result"}},"pos":5,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":7,"id":"68b28e","input":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":8,"id":"5b6b06","input":"# Neural Net classifier\n\n# choose model parameters\nhidden_units = [128,64,32]\n\n# check if we have cuda available\ndevice = 'cuda'\n\n# Map labels to range starting from 0\ndf_BSD_label_mapped = df_balanced_bsd.copy()\n\n# Neural net training for binary classification expects labels to start at 0\ndf_BSD_label_mapped['sha'] = df_BSD_label_mapped['sha'].map({4: 0, 9: 1})\n\n# choose training parameters\nloss_func = nn.CrossEntropyLoss()\nnum_epochs = 100\nlr = 0.001\nevaluator = accuracy_score\n\n# Initialize an empty DataFrame to store the results\nresults_df_nn = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n\nfor i in range(len(bsd_features)-1):\n    print(f'Running model without {bsd_features[i]}..')\n    df_sub = df_BSD_label_mapped.drop(columns=[bsd_features[i]])\n    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sha', if_regression=False)\n    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sha', device, if_regression=False, random_state=seed)\n    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n    print(f\"Test accuracy: {acc:0.3f}\")\n    print('----------------------------------')\n    \n   # Append the results to the DataFrame\n    results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)","output":{"0":{"name":"stdout","output_type":"stream","text":"Running model without special_value..\nThe input dimension is 104 and the output dimension is 2.\n"},"1":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 24 with Training CrossEntropyLoss : 0.0692, Validation CrossEntropyLoss : 0.1201. Training accuracy_score : 0.9732, Validation accuracy_score : 0.9533, to ../trained_models/model.pth.\nTest accuracy: 0.949\n----------------------------------\nRunning model without torsion..\nThe input dimension is 104 and the output dimension is 2.\n"},"2":{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_789/125803182.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)\n"},"3":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 70 with Training CrossEntropyLoss : 0.0740, Validation CrossEntropyLoss : 0.1337. Training accuracy_score : 0.9749, Validation accuracy_score : 0.9595, to ../trained_models/model.pth.\nTest accuracy: 0.957\n----------------------------------\nRunning model without real_period..\nThe input dimension is 104 and the output dimension is 2.\n"},"4":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 7 with Training CrossEntropyLoss : 0.5533, Validation CrossEntropyLoss : 0.6082. Training accuracy_score : 0.7043, Validation accuracy_score : 0.6516, to ../trained_models/model.pth.\nTest accuracy: 0.656\n----------------------------------\nRunning model without regulator..\nThe input dimension is 104 and the output dimension is 2.\n"},"5":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 26 with Training CrossEntropyLoss : 0.0381, Validation CrossEntropyLoss : 0.0581. Training accuracy_score : 0.9836, Validation accuracy_score : 0.9770, to ../trained_models/model.pth.\nTest accuracy: 0.974\n----------------------------------\nRunning model without tamagawa_product..\nThe input dimension is 104 and the output dimension is 2.\n"},"6":{"name":"stdout","output_type":"stream","text":"Save the model from epoch 6 with Training CrossEntropyLoss : 0.4488, Validation CrossEntropyLoss : 0.5432. Training accuracy_score : 0.7930, Validation accuracy_score : 0.7247, to ../trained_models/model.pth.\nTest accuracy: 0.725\n----------------------------------\n"}},"pos":7,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":9,"id":"5b2770","input":"print(results_df_nn)","output":{"0":{"name":"stdout","output_type":"stream","text":"    Feature Deleted  Accuracy\n0     special_value  0.949286\n1           torsion  0.956524\n2       real_period  0.656107\n3         regulator  0.974321\n4  tamagawa_product  0.725411\n"}},"pos":8,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"662f88","input":"# 2. Delete one BSD feature at a time (on original data).\n\nThe models achieve accuracy over 90% when removing one of the following: special value, torsion, and regulator.","pos":5.5,"type":"cell"}
{"cell_type":"markdown","id":"7fc24f","input":"This notebook is for a NN experiment on curves with size of the Tate-Shafarevich group equal to 4 and 9 including BSD features and the first 100 ap coefficients, while removing one feature at a time. The experiment is done on the original data.","pos":-1,"type":"cell"}
{"cell_type":"markdown","id":"96739c","input":"# 1. Create balanced dataset of elliptic curves with size of the Tate-Shafarevich group equal to 4 and 9 containing all BSD features and the first 100 ap coefficients.","pos":0.5,"type":"cell"}
{"id":0,"time":1734134360734,"type":"user"}
{"last_load":1734113439623,"type":"file"}