{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73cd9d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This notebook is for a neural network (NN) on curves with positive rank and size of Sha equal to 1 and 4 and removing one BSD feature at a time. This includes both the original and log-transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8479",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from lib import utils, models, executor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# fix the seed for reproducibility\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f0fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Create balanced dataset of elliptic curves with size of the Tate-Shafarevich group equal to 4 and 9 containing all BSD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50274b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the dataset with 120 features and 3064705 curves..\n"
     ]
    }
   ],
   "source": [
    "# load your data here. The following ensure this will work on Windows as well as Unix\n",
    "path = Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000_reg.parquet\"\n",
    "df = utils.load_data(path)\n",
    "df=df[df['rank']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57fb4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sha\n",
       "1    18710\n",
       "4    18710\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_4 = df[df['sha'] == 4].shape[0]\n",
    "df_balanced = df[df['sha'] == 1].sample(len_4, random_state=seed) \n",
    "df_balanced = pd.concat([df_balanced, df[df['sha'] == 4]])\n",
    "df_balanced.sha.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a706",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Get columns with all the BSD features, from which we will eventually remove one at a time\n",
    "bsd_features = ['special_value', 'torsion', 'real_period', 'regulator', 'tamagawa_product', 'sha']\n",
    "\n",
    "df_balanced_bsd = df_balanced[bsd_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e4fc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>special_value</th>\n",
       "      <th>torsion</th>\n",
       "      <th>real_period</th>\n",
       "      <th>regulator</th>\n",
       "      <th>tamagawa_product</th>\n",
       "      <th>sha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393967</th>\n",
       "      <td>7.08730</td>\n",
       "      <td>4</td>\n",
       "      <td>0.87493</td>\n",
       "      <td>8.10043</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811492</th>\n",
       "      <td>5.28675</td>\n",
       "      <td>2</td>\n",
       "      <td>0.31006</td>\n",
       "      <td>1.70505</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872987</th>\n",
       "      <td>9.43579</td>\n",
       "      <td>1</td>\n",
       "      <td>1.05987</td>\n",
       "      <td>2.22569</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761927</th>\n",
       "      <td>2.52192</td>\n",
       "      <td>2</td>\n",
       "      <td>0.54553</td>\n",
       "      <td>0.57786</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647019</th>\n",
       "      <td>5.41466</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31870</td>\n",
       "      <td>4.24740</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         special_value  torsion  real_period  regulator  tamagawa_product  sha\n",
       "393967         7.08730        4      0.87493    8.10043                16    1\n",
       "811492         5.28675        2      0.31006    1.70505                40    1\n",
       "872987         9.43579        1      1.05987    2.22569                 4    1\n",
       "761927         2.52192        2      0.54553    0.57786                32    1\n",
       "2647019        5.41466        1      0.31870    4.24740                 4    1"
      ]
     },
     "execution_count": 5,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_bsd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e542",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Delete one feature at a time on original data\n",
    "The best accuracy is about 88% when removing the special value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394d4a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07264c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model without special_value..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 79 with Training CrossEntropyLoss : 0.2059, Validation CrossEntropyLoss : 0.2112. Training accuracy_score : 0.8807, Validation accuracy_score : 0.8784, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.885\n",
      "----------------------------------\n",
      "Running model without torsion..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1277/1887803710.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 85 with Training CrossEntropyLoss : 0.4198, Validation CrossEntropyLoss : 0.4357. Training accuracy_score : 0.8020, Validation accuracy_score : 0.7982, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.799\n",
      "----------------------------------\n",
      "Running model without real_period..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 90 with Training CrossEntropyLoss : 0.4696, Validation CrossEntropyLoss : 0.4714. Training accuracy_score : 0.7798, Validation accuracy_score : 0.7805, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.776\n",
      "----------------------------------\n",
      "Running model without regulator..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 79 with Training CrossEntropyLoss : 0.3897, Validation CrossEntropyLoss : 0.3962. Training accuracy_score : 0.8287, Validation accuracy_score : 0.8259, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.823\n",
      "----------------------------------\n",
      "Running model without tamagawa_product..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 92 with Training CrossEntropyLoss : 0.4916, Validation CrossEntropyLoss : 0.5029. Training accuracy_score : 0.7684, Validation accuracy_score : 0.7642, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.765\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Neural Net classifier\n",
    "\n",
    "# choose model parameters\n",
    "hidden_units = [128,64,32]\n",
    "\n",
    "# check if we have cuda available\n",
    "device = 'cuda'\n",
    "\n",
    "# Map labels to range starting from 0\n",
    "df_BSD_label_mapped = df_balanced_bsd.copy()\n",
    "\n",
    "# Neural net training for binary classification expects labels to start at 0\n",
    "df_BSD_label_mapped['sha'] = df_BSD_label_mapped['sha'].map({1: 0, 4: 1})\n",
    "\n",
    "# choose training parameters\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "evaluator = accuracy_score\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results_df_nn = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n",
    "\n",
    "for i in range(len(bsd_features)-1):\n",
    "    print(f'Running model without {bsd_features[i]}..')\n",
    "    df_sub = df_BSD_label_mapped.drop(columns=[bsd_features[i]])\n",
    "    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sha', if_regression=False)\n",
    "    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n",
    "    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sha', device, if_regression=False, random_state=seed)\n",
    "    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n",
    "    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n",
    "    print(f\"Test accuracy: {acc:0.3f}\")\n",
    "    print('----------------------------------')\n",
    "    \n",
    "   # Append the results to the DataFrame\n",
    "    results_df_nn = pd.concat([results_df_nn, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a0f4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature Deleted  Accuracy\n",
      "0     special_value  0.884687\n",
      "1           torsion  0.799172\n",
      "2       real_period  0.776323\n",
      "3         regulator  0.822688\n",
      "4  tamagawa_product  0.765366\n"
     ]
    }
   ],
   "source": [
    "print(results_df_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff38",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3. Delete one feature at a time on log-transformed data\n",
    "\n",
    "The best accuracy is about 92% when removing the special value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d386",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model without special_value..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 21 with Training CrossEntropyLoss : 0.1895, Validation CrossEntropyLoss : 0.1884. Training accuracy_score : 0.9225, Validation accuracy_score : 0.9253, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.922\n",
      "----------------------------------\n",
      "Running model without torsion..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1277/2569573343.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df_nn_log = pd.concat([results_df_nn_log, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 91 with Training CrossEntropyLoss : 0.3967, Validation CrossEntropyLoss : 0.4151. Training accuracy_score : 0.8180, Validation accuracy_score : 0.8111, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.818\n",
      "----------------------------------\n",
      "Running model without real_period..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 88 with Training CrossEntropyLoss : 0.4617, Validation CrossEntropyLoss : 0.4650. Training accuracy_score : 0.7821, Validation accuracy_score : 0.7827, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.778\n",
      "----------------------------------\n",
      "Running model without regulator..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 83 with Training CrossEntropyLoss : 0.3831, Validation CrossEntropyLoss : 0.3917. Training accuracy_score : 0.8303, Validation accuracy_score : 0.8294, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.827\n",
      "----------------------------------\n",
      "Running model without tamagawa_product..\n",
      "The input dimension is 4 and the output dimension is 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the model from epoch 84 with Training CrossEntropyLoss : 0.4768, Validation CrossEntropyLoss : 0.4876. Training accuracy_score : 0.7746, Validation accuracy_score : 0.7687, to ../trained_models/model.pth.\n",
      "Test accuracy: 0.773\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Neural Net classifier on log-transformed data\n",
    "\n",
    "# choose model parameters\n",
    "hidden_units = [128,64,32]\n",
    "\n",
    "# check if we have cuda available\n",
    "device = 'cuda'\n",
    "\n",
    "# Map labels to range starting from 0\n",
    "df_BSD_label_mapped = df_balanced_bsd.copy()\n",
    "for col in bsd_features[:-1]:\n",
    "    df_BSD_label_mapped[col]=df_BSD_label_mapped[col].apply(np.log)\n",
    "\n",
    "# Neural net training for binary classification expects labels to start at 0\n",
    "df_BSD_label_mapped['sha'] = df_BSD_label_mapped['sha'].map({1: 0, 4: 1})\n",
    "\n",
    "# choose training parameters\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "evaluator = accuracy_score\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results_df_nn_log = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n",
    "\n",
    "for i in range(len(bsd_features)-1):\n",
    "    print(f'Running model without {bsd_features[i]}..')\n",
    "    df_sub = df_BSD_label_mapped.drop(columns=[bsd_features[i]])\n",
    "    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sha', if_regression=False)\n",
    "    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n",
    "    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sha', device, if_regression=False, random_state=seed)\n",
    "    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n",
    "    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n",
    "    print(f\"Test accuracy: {acc:0.3f}\")\n",
    "    print('----------------------------------')\n",
    "    \n",
    "   # Append the results to the DataFrame\n",
    "    results_df_nn_log = pd.concat([results_df_nn_log, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': acc}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba356",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature Deleted  Accuracy\n",
      "0     special_value  0.922234\n",
      "1           torsion  0.818413\n",
      "2       real_period  0.778193\n",
      "3         regulator  0.826697\n",
      "4  tamagawa_product  0.772582\n"
     ]
    }
   ],
   "source": [
    "print(results_df_nn_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "6111cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "1ba1c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "sage",
    "--python",
    "-m",
    "ipykernel",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "--matplotlib=inline",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (SageMath)",
   "env": {
   },
   "language": "python",
   "name": "python3-sage",
   "resource_dir": "/opt/venv/share/jupyter/kernels/python3-sage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}