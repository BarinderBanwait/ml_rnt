{"backend_state":"ready","kernel":"python3-sage","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_ipynb_save":1734134349455,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"82a130","input":"","pos":13,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":11,"id":"e7305b","input":"from lib import utils, models, executor\nimport torch.nn as nn\nimport torch.optim as optim\nfrom pathlib import Path\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# fix the seed for reproducibility\nseed = 42","pos":1,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":15,"id":"8c29ee","input":"df_balanced_bsd.head(5)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>special_value</th>\n      <th>torsion</th>\n      <th>real_period</th>\n      <th>regulator</th>\n      <th>tamagawa_product</th>\n      <th>sha</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>334625</th>\n      <td>2.19751</td>\n      <td>2</td>\n      <td>0.54938</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1086182</th>\n      <td>3.22805</td>\n      <td>1</td>\n      <td>0.80701</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1782926</th>\n      <td>3.98612</td>\n      <td>2</td>\n      <td>0.49826</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2484030</th>\n      <td>2.99537</td>\n      <td>1</td>\n      <td>0.09361</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3053287</th>\n      <td>2.23394</td>\n      <td>1</td>\n      <td>0.09308</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"         special_value  torsion  real_period  regulator  tamagawa_product  sha\n334625         2.19751        2      0.54938        1.0                 4    4\n1086182        3.22805        1      0.80701        1.0                 1    4\n1782926        3.98612        2      0.49826        1.0                 8    4\n2484030        2.99537        1      0.09361        1.0                 8    4\n3053287        2.23394        1      0.09308        1.0                 6    4"},"exec_count":15,"output_type":"execute_result"}},"pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":18,"id":"e6f4a5","input":"# Initialize an empty DataFrame to store the results\nresults_df_lr = pd.DataFrame({\n    'Feature Deleted': pd.Series(dtype='str'),\n    'Accuracy': pd.Series(dtype='float')})\n\n\nfor i in range(len(bsd_features[:-1])):\n    print(f'Running model without {bsd_features[i]}..')\n    df_sub = df_balanced_bsd.drop(columns=[bsd_features[i]]).copy()\n    X = df_sub[[c for c in df_sub.columns if c != 'sha']]\n    y = df_sub['sha']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    \n   # Append the results to the DataFrame\n    results_df_lr = pd.concat([results_df_lr, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': accuracy}])], ignore_index=True)\n    \nprint(results_df_lr)","output":{"0":{"name":"stdout","output_type":"stream","text":"Running model without special_value..\n"},"1":{"name":"stdout","output_type":"stream","text":"Running model without torsion..\n"},"2":{"name":"stdout","output_type":"stream","text":"Running model without real_period..\n"},"3":{"name":"stdout","output_type":"stream","text":"Running model without regulator..\n"},"4":{"name":"stdout","output_type":"stream","text":"Running model without tamagawa_product..\n    Feature Deleted  Accuracy\n0     special_value  0.613722\n1           torsion  0.646589\n2       real_period  0.609310\n3         regulator  0.613425\n4  tamagawa_product  0.650109\n"}},"pos":9,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":19,"id":"a31f27","input":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","pos":11,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":2,"id":"f01dce","input":"# load your data here. The following ensure this will work on Windows as well as Unix\npath = Path(\"..\") / \"data_files\" / \"sha\"/ \"ecq_sha_B_100_conds_1_500000_reg.parquet\"\ndf = utils.load_data(path)","output":{"0":{"name":"stdout","output_type":"stream","text":"Loaded the dataset with 120 features and 3064705 curves..\n"}},"pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":23,"id":"ef5dfa","input":"# Initialize an empty DataFrame to store the results\nresults_df_lr = pd.DataFrame({\n    'Feature Deleted': pd.Series(dtype='str'),\n    'Accuracy': pd.Series(dtype='float')})\n\n\nfor i in range(len(bsd_features[:-1])):\n    print(f'Running model without {bsd_features[i]}..')\n    df_sub_log = df_balanced_bsd.drop(columns=[bsd_features[i]]).copy()\n    print\n    X = df_sub_log[[c for c in df_sub_log.columns if c != 'sha']].apply(np.log)\n    y = df_sub_log['sha']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    \n   # Append the results to the DataFrame\n    results_df_lr = pd.concat([results_df_lr, pd.DataFrame([{'Feature Deleted': bsd_features[i], 'Accuracy': accuracy}])], ignore_index=True)\n    \nprint(results_df_lr)","output":{"0":{"name":"stdout","output_type":"stream","text":"Running model without special_value..\nRunning model without torsion..\n"},"1":{"name":"stdout","output_type":"stream","text":"Running model without real_period..\nRunning model without regulator..\n"},"2":{"name":"stdout","output_type":"stream","text":"Running model without tamagawa_product..\n    Feature Deleted  Accuracy\n0     special_value  0.697849\n1           torsion  0.716984\n2       real_period  0.610946\n3         regulator  0.948493\n4  tamagawa_product  0.642871\n"}},"pos":12,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"4c1a64","input":"len_9 = df[df['sha'] == 9].shape[0]\ndf_balanced = df[df['sha'] == 4].sample(len_9, random_state=seed) \ndf_balanced = pd.concat([df_balanced, df[df['sha'] == 9]])\ndf_balanced.sha.value_counts()","output":{"0":{"data":{"text/plain":"sha\n4    50428\n9    50428\nName: count, dtype: int64"},"exec_count":4,"output_type":"execute_result"}},"pos":4,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":5,"id":"8f89a2","input":"#Get columns with all the BSD features, from which we will eventually remove one at a time\nbsd_features = ['special_value', 'torsion', 'real_period', 'regulator', 'tamagawa_product', 'sha']\n\ndf_balanced_bsd = df_balanced[bsd_features].copy()","pos":5,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":9,"id":"3c2994","input":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","pos":8,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1bdd70","input":"This notebook is for logistic regression on curves with size of Sha equal to 4 and 9 and removing one BSD feature at a time. This includes both the original and log-transformed data.","pos":0,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"22b838","input":"# 2. Delete one feature at a time on original data\n\nThe best accuracy is about 65%.","pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"bc87d3","input":"# 3. Delete one feature at a time on log-transformed data\n\nNow, the best accuracy is at ~95% for missing regulator.","pos":10,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"eb0cfa","input":"# 1. Create balanced dataset of elliptic curves with size of the Tate-Shafarevich group equal to 4 and 9 containing all BSD features","pos":2,"state":"done","type":"cell"}
{"id":0,"time":1734133789503,"type":"user"}
{"last_load":1734037447628,"type":"file"}