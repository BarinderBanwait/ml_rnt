{"backend_state":"running","connection_file":"/projects/bda83a78-8667-461e-b29a-519419abf9c8/.local/share/jupyter/runtime/kernel-e1def400-fe53-4349-b6c2-8d9fee1e413e.json","kernel":"python3-sage","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_ipynb_save":1729871486831,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1729861112223,"exec_count":19,"id":"117a4b","input":"from lib import utils\nfrom lib import models\nfrom lib import executor\nfrom lib.utils import nearest_integer_acc\n\nimport torch\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score","kernel":"python3-sage","pos":0,"start":1729861112220,"state":"done","type":"cell"}
{"cell_type":"code","end":1729861112230,"exec_count":20,"id":"290534","input":"torch.cuda.set_device(2)","kernel":"python3-sage","pos":1,"start":1729861112225,"state":"done","type":"cell"}
{"cell_type":"code","end":1729861116417,"exec_count":21,"id":"75af9e","input":"# load your data here. The following ensure this will work on Windows as well as Unix\n# the data file has its Kodaira symbols already preprocessed \npath = '../data_files/sha/ecq_sha_B_100_conds_1_500000_reg.parquet'\ndf = utils.load_data(path)\n\n# dropping columns that are not needed\ndf.drop(['conductor','adelic_level','lmfdb_label'], axis=1, inplace=True)\n\n# get rank great than 0 curves\ndf = df[df['rank'] > 0]\nprint('Now, leaving out the rank 0 curves.')\n\n# get square root of order of sha\ndf['sqrt_sha'] = df['sha'].apply(lambda x: int(x**0.5))\ndf.drop('sha', axis=1, inplace=True)\nprint(f'Values counts of the square root of order of sha: ')\nprint(df.sqrt_sha.value_counts())","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Loaded the dataset with 120 features and 3064705 curves..\n"},"1":{"name":"stdout","text":"Now, leaving out the rank 0 curves.\n"},"2":{"name":"stdout","text":"Values counts of the square root of order of sha: \nsqrt_sha\n1    1873224\n2      18710\n3       1462\n4        323\n5         96\n7          9\n8          3\n6          2\nName: count, dtype: int64\n"}},"pos":2,"start":1729861112235,"state":"done","type":"cell"}
{"cell_type":"code","end":1729861116493,"exec_count":26,"id":"9bf668","input":"# Map labels to range starting from 0\ndf_BSD['sqrt_sha'] = df_BSD['sqrt_sha'].map({2: 0, 3: 1})","kernel":"python3-sage","pos":8,"start":1729861116491,"state":"done","type":"cell"}
{"cell_type":"code","end":1729861132375,"exec_count":27,"id":"b12ba4","input":"# split data\ntrain_dataloader, val_dataset, test_dataset = utils.prepare_data(df_BSD, 'sqrt_sha', device, if_regression=False, random_state=seed)\n# train the model\nmodel, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n# plot train_eval_hist, val_eval_hist\nutils.plot_train_eval_hist(train_eval_hist, val_eval_hist, title='All BSD Features - Train and Validation Accuracy')","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Save the model from epoch 99 with Training CrossEntropyLoss : 0.0537, Validation CrossEntropyLoss : 0.0865. Training accuracy_score : 0.9635, Validation accuracy_score : 0.9538, to ../trained_models/model.pth.\n"},"1":{"data":{"image/png":"c093ad6dde1d4cc006f9ea608356c6f4373c7144","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1010}}}},"pos":9,"start":1729861116499,"state":"done","type":"cell"}
{"cell_type":"code","end":1729861132865,"exec_count":28,"id":"62c2ff","input":"utils.plot_train_loss_hist(train_loss_hist, val_loss_hist, title='All BSD Features - Train and Validation Loss')","kernel":"python3-sage","output":{"0":{"data":{"image/png":"01470ccac81b54d0b602cd92474730bd92a4ad7d","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1001}}}},"pos":10,"start":1729861132393,"state":"done","type":"cell"}
{"cell_type":"code","end":1729861132874,"exec_count":29,"id":"70f4c2","input":"acc = executor.test(model, test_dataset, evaluator, if_regression = False)\nprint(f\"Test accuracy: {acc:0.4f}\")","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Test accuracy: 0.9556\n"}},"pos":11,"start":1729861132869,"state":"done","type":"cell"}
{"cell_type":"code","end":1729861132882,"exec_count":30,"id":"de8ef3","input":"# write a list of lists where each list is taking one feature out\n# this is for the purpose of feature importance\nfeatures = ['special_value', 'torsion', 'regulator', 'real_period', 'tamagawa_product']\nfeatures_list = []\nmissing_feature = []\nfor i in range(len(features)):\n    missing_feature.append(features[i])\n    features_list.append([x for x in features if x != features[i]]+['sqrt_sha'])","kernel":"python3-sage","pos":13,"start":1729861132880,"state":"done","type":"cell"}
{"cell_type":"code","end":1729861212553,"exec_count":31,"id":"2ce86d","input":"# Initialize an empty DataFrame to store the results\nresults_df = pd.DataFrame(columns=['Feature Deleted', 'Accuracy'])\n\nfor i in range(len(features_list)):\n    print(f'Running model without {missing_feature[i]}..')\n    df_sub = df_BSD.drop(columns=[missing_feature[i]])\n    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sqrt_sha', if_regression=False)\n    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sqrt_sha', device, if_regression=False, random_state=seed)\n    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=False, verbose=False)\n    # plot train_eval_hist, val_eval_hist\n    utils.plot_train_eval_hist(train_eval_hist, val_eval_hist, title=f'Missing {missing_feature[i]} - Train and Validation Accuracy', show = False)\n    utils.plot_train_loss_hist(train_loss_hist, val_loss_hist, title=f'Missing {missing_feature[i]} - Train and Validation Loss', show = False)\n    acc = executor.test(model, test_dataset, evaluator, if_regression=False)\n    print(f\"Test accuracy: {acc:0.4f}\")\n    print('----------------------------------')\n    \n   # Append the results to the DataFrame\n    results_df = pd.concat([results_df, pd.DataFrame([{'Feature Deleted': missing_feature[i], 'Accuracy': acc}])], ignore_index=True)","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Running model without special_value..\nThe input dimension is 4 and the output dimension is 2.\n"},"1":{"name":"stdout","text":"Save the model from epoch 91 with Training CrossEntropyLoss : 0.3360, Validation CrossEntropyLoss : 0.3392. Training accuracy_score : 0.8158, Validation accuracy_score : 0.8103, to ../trained_models/model.pth.\n"},"10":{"name":"stdout","text":"Save the model from epoch 99 with Training CrossEntropyLoss : 0.3619, Validation CrossEntropyLoss : 0.4112. Training accuracy_score : 0.8324, Validation accuracy_score : 0.8085, to ../trained_models/model.pth.\n"},"11":{"name":"stdout","text":"Test accuracy: 0.8171\n----------------------------------\n"},"12":{"data":{"image/png":"4788bc76185438051b14fc15db75a92f430385ac","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1010}}},"13":{"data":{"image/png":"b28edd76a9d40235681cbc1a41851041fb9bb746","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1010}}},"14":{"data":{"image/png":"6f57a7b21774eeb4afcf92df75bf323bd3569712","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1010}}},"15":{"data":{"image/png":"d2bdfe6fd7e5d414aae8b882064946e997c34f19","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1010}}},"16":{"data":{"image/png":"6ec0c71dcdad8c09ac57e5100b24d5c837a2923f","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1010}}},"17":{"data":{"image/png":"2c1abb608404505f92ae1fc64b754869b76abba8","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1010}}},"18":{"data":{"image/png":"05a3d73c866b47919029d4f2965e29794be44e4a","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1010}}},"19":{"data":{"image/png":"36aed50f0f5c6dcd6ed26e22738449251b044e8f","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1018}}},"2":{"name":"stdout","text":"Test accuracy: 0.8154\n----------------------------------\nRunning model without torsion..\nThe input dimension is 4 and the output dimension is 2.\n"},"20":{"data":{"image/png":"1be1287fadf3b4a36939e1b32f442224ba7fa7d0","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1010}}},"21":{"data":{"image/png":"5bbe60555abbede35f8a29551ba9e41c60d634f8","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1018}}},"3":{"name":"stderr","text":"/tmp/ipykernel_1890490/1531375221.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df = pd.concat([results_df, pd.DataFrame([{'Feature Deleted': missing_feature[i], 'Accuracy': acc}])], ignore_index=True)\n"},"4":{"name":"stdout","text":"Save the model from epoch 90 with Training CrossEntropyLoss : 0.1984, Validation CrossEntropyLoss : 0.2403. Training accuracy_score : 0.9151, Validation accuracy_score : 0.8974, to ../trained_models/model.pth.\n"},"5":{"name":"stdout","text":"Test accuracy: 0.9145\n----------------------------------\nRunning model without regulator..\nThe input dimension is 4 and the output dimension is 2.\n"},"6":{"name":"stdout","text":"Save the model from epoch 55 with Training CrossEntropyLoss : 0.3618, Validation CrossEntropyLoss : 0.3957. Training accuracy_score : 0.8398, Validation accuracy_score : 0.8171, to ../trained_models/model.pth.\n"},"7":{"name":"stdout","text":"Test accuracy: 0.8308\n----------------------------------\nRunning model without real_period..\nThe input dimension is 4 and the output dimension is 2.\n"},"8":{"name":"stdout","text":"Save the model from epoch 49 with Training CrossEntropyLoss : 0.4136, Validation CrossEntropyLoss : 0.4640. Training accuracy_score : 0.8153, Validation accuracy_score : 0.7949, to ../trained_models/model.pth.\n"},"9":{"name":"stdout","text":"Test accuracy: 0.8256\n----------------------------------\nRunning model without tamagawa_product..\nThe input dimension is 4 and the output dimension is 2.\n"}},"pos":14,"start":1729861132891,"state":"done","type":"cell"}
{"cell_type":"code","end":1729861212566,"exec_count":32,"id":"d1fce7","input":"print(results_df)","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"    Feature Deleted  Accuracy\n0     special_value  0.815385\n1           torsion  0.914530\n2         regulator  0.830769\n3       real_period  0.825641\n4  tamagawa_product  0.817094\n"}},"pos":15,"start":1729861212563,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":22,"id":"2328da","input":"# to get a balanced dataset with equal amount of 1 and 4 labels\nlen_9 = df[df['sqrt_sha'] == 3].shape[0]\ndf_balanced = df[df['sqrt_sha'] == 2].sample(len_9) \ndf_balanced = pd.concat([df_balanced, df[df['sqrt_sha'] == 3]])\nprint(f'Values counts of the square root of order of sha: ')\ndf_balanced.sqrt_sha.value_counts()","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Values counts of the square root of order of sha: \n"},"1":{"data":{"text/plain":"sqrt_sha\n2    1462\n3    1462\nName: count, dtype: int64"},"exec_count":22}},"pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":23,"id":"459aad","input":"# Select your features\n\n# BSD Features\ndf_BSD = df_balanced[['special_value', 'torsion', 'regulator', 'real_period', 'tamagawa_product','sqrt_sha']].copy()\n\n# fix the seed for reproducibility\nseed = 42","kernel":"python3-sage","pos":4,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":24,"id":"ec8968","input":"# choose model parameters\nhidden_units = [128,64,32]\n\n# check if we have cuda available\ndevice = 'cuda'\n\n# default model parameters\ninput_dim, output_dim = utils.get_input_output_dim(df_BSD, 'sqrt_sha', if_regression=False)\n\n# create model\nmodel = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n# model = models.VanillaNN(input_dim, hidden_units, output_dim).to(device)\n\n# print model summary\nutils.model_summary(model)","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"The input dimension is 5 and the output dimension is 2.\nThe model has 11,618 trainable parameters..\nVanillaNN(\n  (layers): ModuleList(\n    (0): Linear(in_features=5, out_features=128, bias=True)\n    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Linear(in_features=128, out_features=64, bias=True)\n    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): Linear(in_features=32, out_features=2, bias=True)\n  )\n)\n"}},"pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":25,"id":"ed5924","input":"# choose training parameters\nloss_func = nn.CrossEntropyLoss()\nnum_epochs = 100\nlr = 0.001\noptimizer = optim.Adam(model.parameters(), lr=lr)\nevaluator = accuracy_score","kernel":"python3-sage","pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4a04b9","input":"# now delete one feature per time to test feature importance","pos":12,"type":"cell"}
{"cell_type":"markdown","id":"df13fd","input":"# first run an experiment using all variables from BSD formula","pos":5,"type":"cell"}
{"id":0,"time":1729799039004,"type":"user"}
{"last_load":1729799039215,"type":"file"}