{"backend_state":"running","connection_file":"/projects/bda83a78-8667-461e-b29a-519419abf9c8/.local/share/jupyter/runtime/kernel-57db4d81-3602-4d4f-b654-72edc588a01a.json","kernel":"python3-sage","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_ipynb_save":1729862183446,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":10,"id":"62c2ff","input":"utils.plot_train_loss_hist(train_loss_hist, val_loss_hist, title='All BSD Features - Train and Validation Loss')","kernel":"python3-sage","output":{"0":{"data":{"image/png":"f8c2c7284173dee89d1cd063d565fccaa38e5fed","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":988}}}},"pos":8,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":11,"id":"ed0308","input":"acc = executor.test(model, test_dataset, evaluator, if_regression = True)\nmae = executor.test(model, test_dataset, mean_absolute_error, if_regression = True)\nmse = executor.test(model, test_dataset, mean_squared_error, if_regression = True)\nprint(f\"Test accuracy: {acc:0.4f}\")\nprint(f\"Test Mean Absolute Error: {mae:0.4f}. Test Mean Squared Error: {mse:0.4f}\")","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Test accuracy: 0.9504\nTest Mean Absolute Error: 0.1179. Test Mean Squared Error: 0.0436\n"}},"pos":9,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":12,"id":"de8ef3","input":"# write a list of lists where each list is taking one feature out\n# this is for the purpose of feature importance\nfeatures = ['special_value', 'torsion', 'regulator', 'real_period', 'tamagawa_product']\nfeatures_list = []\nmissing_feature = []\nfor i in range(len(features)):\n    missing_feature.append(features[i])\n    features_list.append([x for x in features if x != features[i]]+['sqrt_sha'])","kernel":"python3-sage","pos":11,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":13,"id":"2ce86d","input":"# Initialize an empty DataFrame to store the results\nresults_df = pd.DataFrame(columns=['Feature Deleted', 'Accuracy', 'MAE', 'MSE'])\n\nfor i in range(len(features_list)):\n    print(f'Running model without {missing_feature[i]}..')\n    df_sub = df_BSD.drop(columns=[missing_feature[i]])\n    input_dim, output_dim = utils.get_input_output_dim(df_sub, 'sqrt_sha', if_regression=True)\n    model = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr) # reinitialize optimizer\n    train_dataloader, val_dataset, test_dataset = utils.prepare_data(df_sub, 'sqrt_sha', device, if_regression=True, random_state=seed)\n    model, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=True, verbose=False)\n    # plot train_eval_hist, val_eval_hist\n    utils.plot_train_eval_hist(train_eval_hist, val_eval_hist, title=f'Missing {missing_feature[i]} - Train and Validation Accuracy', show = False)\n    utils.plot_train_loss_hist(train_loss_hist, val_loss_hist, title=f'Missing {missing_feature[i]} - Train and Validation Loss', show = False)\n    acc = executor.test(model, test_dataset, evaluator, if_regression=True)\n    mae = executor.test(model, test_dataset, mean_absolute_error, if_regression=True)\n    mse = executor.test(model, test_dataset, mean_squared_error, if_regression=True)\n    print(f\"Test accuracy: {acc:0.4f}\")\n    print(f\"Test Mean Absolute Error: {mae:0.4f}. Test Mean Squared Error: {mse:0.4f}\")\n    print('----------------------------------')\n    \n    # Append the results to the DataFrame\n    results_df = pd.concat([results_df, pd.DataFrame([{'Feature Deleted': missing_feature[i], 'Accuracy': acc, 'MAE': mae, 'MSE': mse}])], ignore_index=True)","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Running model without special_value..\nThe input dimension is 4 and the output dimension is 1.\n"},"1":{"name":"stdout","text":"Save the model from epoch 68 with Training MSELoss : 0.1110, Validation MSELoss : 0.1208. Training nearest_integer_acc : 0.7617, Validation nearest_integer_acc : 0.7675, to ../trained_models/model.pth.\n"},"10":{"name":"stdout","text":"Save the model from epoch 69 with Training MSELoss : 0.1257, Validation MSELoss : 0.1343. Training nearest_integer_acc : 0.8198, Validation nearest_integer_acc : 0.8137, to ../trained_models/model.pth.\n"},"11":{"name":"stdout","text":"Test accuracy: 0.7949\nTest Mean Absolute Error: 0.2908. Test Mean Squared Error: 0.1494\n----------------------------------\n"},"12":{"data":{"image/png":"865bd8958274327a1b83d3a991e43e88af78ab58","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1001}}},"13":{"data":{"image/png":"cd26bb2952cf02d8c082adbedecf9f605e636dcc","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":988}}},"14":{"data":{"image/png":"032abaef55e26f822810491d20b323ad9289cb7c","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1001}}},"15":{"data":{"image/png":"9b75ed509e74ef93f7b78d45fcc12c977a641ac3","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":988}}},"16":{"data":{"image/png":"bacec838a377fb05fe474a1b59fee47920a221ff","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1001}}},"17":{"data":{"image/png":"81d8cb12505af783fc8768055bc4e12a5b475791","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":988}}},"18":{"data":{"image/png":"acdf997042f5f1963362cb0c2f9c380852831ee2","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1001}}},"19":{"data":{"image/png":"a4e592ad83b082d0062eeef79d184302f726c115","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":988}}},"2":{"name":"stdout","text":"Test accuracy: 0.7470\nTest Mean Absolute Error: 0.3316. Test Mean Squared Error: 0.1729\n----------------------------------\nRunning model without torsion..\nThe input dimension is 4 and the output dimension is 1.\n"},"20":{"data":{"image/png":"2a68a4b9ef3eacf8051d72f05e9b45d33feb4a13","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1001}}},"21":{"data":{"image/png":"7ad994e804d948cba0aea4cbdc43f1bfac154f71","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":988}}},"3":{"name":"stderr","text":"/tmp/ipykernel_1888419/275750393.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df = pd.concat([results_df, pd.DataFrame([{'Feature Deleted': missing_feature[i], 'Accuracy': acc, 'MAE': mae, 'MSE': mse}])], ignore_index=True)\n"},"4":{"name":"stdout","text":"Save the model from epoch 97 with Training MSELoss : 0.0818, Validation MSELoss : 0.0860. Training nearest_integer_acc : 0.8905, Validation nearest_integer_acc : 0.8581, to ../trained_models/model.pth.\n"},"5":{"name":"stdout","text":"Test accuracy: 0.8718\nTest Mean Absolute Error: 0.2318. Test Mean Squared Error: 0.0967\n----------------------------------\nRunning model without regulator..\nThe input dimension is 4 and the output dimension is 1.\n"},"6":{"name":"stdout","text":"Save the model from epoch 63 with Training MSELoss : 0.1247, Validation MSELoss : 0.1363. Training nearest_integer_acc : 0.8187, Validation nearest_integer_acc : 0.8000, to ../trained_models/model.pth.\n"},"7":{"name":"stdout","text":"Test accuracy: 0.8137\nTest Mean Absolute Error: 0.2910. Test Mean Squared Error: 0.1349\n----------------------------------\nRunning model without real_period..\nThe input dimension is 4 and the output dimension is 1.\n"},"8":{"name":"stdout","text":"Save the model from epoch 47 with Training MSELoss : 0.1387, Validation MSELoss : 0.1585. Training nearest_integer_acc : 0.7965, Validation nearest_integer_acc : 0.7812, to ../trained_models/model.pth.\n"},"9":{"name":"stdout","text":"Test accuracy: 0.7915\nTest Mean Absolute Error: 0.3528. Test Mean Squared Error: 0.1867\n----------------------------------\nRunning model without tamagawa_product..\nThe input dimension is 4 and the output dimension is 1.\n"}},"pos":12,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":23,"id":"d1fce7","input":"print(results_df)","output":{"0":{"name":"stdout","output_type":"stream","text":"    Feature Deleted  Accuracy       MAE       MSE\n0     special_value  0.700972  0.390343  0.192720\n1           torsion  0.959449  0.097990  0.034988\n2         regulator  0.965150  0.071440  0.030399\n3       real_period  0.634692  0.452044  0.223724\n4  tamagawa_product  0.869919  0.248201  0.106204\n"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"117a4b","input":"from lib import utils\nfrom lib import models\nfrom lib import executor\nfrom lib.utils import nearest_integer_acc\n\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error","kernel":"python3-sage","pos":0,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"75af9e","input":"# load your data here. The following ensure this will work on Windows as well as Unix\n# the data file has its Kodaira symbols already preprocessed \npath = '../data_files/sha/ecq_sha_B_100_conds_1_500000_reg.parquet'\ndf = utils.load_data(path)\n\n# dropping columns that are not needed\ndf.drop(['conductor','adelic_level','lmfdb_label'], axis=1, inplace=True)\n\n# get rank great than 0 curves\ndf = df[df['rank'] > 0]\nprint('Now, leaving out the rank 0 curves.')\n\n# get square root of order of sha\ndf['sqrt_sha'] = df['sha'].apply(lambda x: int(x**0.5))\ndf.drop('sha', axis=1, inplace=True)\nprint(f'Values counts of the square root of order of sha: ')\nprint(df.sqrt_sha.value_counts())","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Loaded the dataset with 120 features and 3064705 curves..\n"},"1":{"name":"stdout","text":"Now, leaving out the rank 0 curves.\n"},"2":{"name":"stdout","text":"Values counts of the square root of order of sha: \nsqrt_sha\n1    1873224\n2      18710\n3       1462\n4        323\n5         96\n7          9\n8          3\n6          2\nName: count, dtype: int64\n"}},"pos":1,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":5,"id":"2328da","input":"# to get a balanced dataset with equal amount of 1 and 4 labels\nlen_9 = df[df['sqrt_sha'] == 3].shape[0]\ndf_balanced = df[df['sqrt_sha'] == 2].sample(len_9) \ndf_balanced = pd.concat([df_balanced, df[df['sqrt_sha'] == 3]])\nprint(f'Values counts of the square root of order of sha: ')\ndf_balanced.sqrt_sha.value_counts()","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Values counts of the square root of order of sha: \n"},"1":{"data":{"text/plain":"sqrt_sha\n2    1462\n3    1462\nName: count, dtype: int64"},"exec_count":5}},"pos":2,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":6,"id":"459aad","input":"# Select your features\n\n# BSD Features\ndf_BSD = df_balanced[['special_value', 'torsion', 'regulator', 'real_period', 'tamagawa_product','sqrt_sha']]\n\n# fix the seed for reproducibility\nseed = 42","kernel":"python3-sage","pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":7,"id":"ec8968","input":"# choose model parameters\nhidden_units = [128,64,32]\n\n# check if we have cuda available\ndevice = utils.get_device()\n\n# default model parameters\ninput_dim, output_dim = utils.get_input_output_dim(df_BSD, 'sqrt_sha', if_regression=True)\n\n# create model\nmodel = models.VanillaNN(input_dim, hidden_units, output_dim, if_dropout=False, dropout_rate=0.3, if_batchnorm=True).to(device)\n# model = models.VanillaNN(input_dim, hidden_units, output_dim).to(device)\n\n# print model summary\nutils.model_summary(model)","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Device: cuda.\nThe input dimension is 5 and the output dimension is 1.\nThe model has 11,585 trainable parameters..\nVanillaNN(\n  (layers): ModuleList(\n    (0): Linear(in_features=5, out_features=128, bias=True)\n    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Linear(in_features=128, out_features=64, bias=True)\n    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): Linear(in_features=32, out_features=1, bias=True)\n  )\n)\n"}},"pos":5,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":8,"id":"ed5924","input":"# choose training parameters\nloss_func = nn.MSELoss()\nnum_epochs = 100\nlr = 0.001\noptimizer = optim.Adam(model.parameters(), lr=lr)\nevaluator = nearest_integer_acc","kernel":"python3-sage","pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":9,"id":"b12ba4","input":"# split data\ntrain_dataloader, val_dataset, test_dataset = utils.prepare_data(df_BSD, 'sqrt_sha', device, if_regression=True, random_state=seed)\n# train the model\nmodel, train_eval_hist, val_eval_hist, train_loss_hist, val_loss_hist = executor.train(model, train_dataloader, val_dataset, loss_func, evaluator, optimizer, num_epochs, if_regression=True, verbose=False)\n# plot train_eval_hist, val_eval_hist\nutils.plot_train_eval_hist(train_eval_hist, val_eval_hist, title='All BSD Features - Train and Validation Accuracy')","kernel":"python3-sage","output":{"0":{"name":"stdout","text":"Save the model from epoch 92 with Training MSELoss : 0.0344, Validation MSELoss : 0.0399. Training nearest_integer_acc : 0.9629, Validation nearest_integer_acc : 0.9436, to ../trained_models/model.pth.\n"},"1":{"data":{"image/png":"629ec9049dd5bcda7da79c9d6e211394f9462d44","text/plain":"<Figure size 1200x600 with 1 Axes>"},"metadata":{"image/png":{"height":546,"width":1001}}}},"pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4a04b9","input":"# now delete one feature per time to test feature importance","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"df13fd","input":"# first run an experiment using all variables from BSD formula","pos":4,"type":"cell"}
{"id":0,"time":1729798113136,"type":"user"}
{"last_load":1729798256466,"type":"file"}